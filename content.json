{"pages":[{"title":"categories","text":"","link":"/categories/index.html"}],"posts":[{"title":"从以太坊交易日志中监听智能合约事件event","text":"以太坊智能合约中，有一类特殊的回调函数，没有函数体，以大写字母开头，一般用来记录函数状态，这类回调函数称为事件event。事件event由合约函数调用，web3.js可以轻松监听此类event，并返回需要的数据。在网上搜索到的相关文章都是关于用web3.js来实现监听event的，今天我们就来从c++代码层面来看看怎么实现这个功能。 我们先来看看一个简单的智能合约例子： 1234567891011121314contract Contract { event Incremented(bool indexed odd, uint x, uint y); function Contract() { x = 69; y = 20; } function inc() { ++x; ++y; Incremented(x % 2 == 0, x, y); } uint x; uint y;} 这个合约只有两个变量x, y，一个函数inc()和一个事件Incremented，如果我们调用Contract中的inc()函数，则事件Incremented会被执行，我们的目的就是监听这个事件。 首先我们在私有链上来部署这个合约，部署的过程就不赘述了，简单说就是执行一笔交易，交易的data为合约的二进制代码。 同样调用智能合约的函数也是向智能合约发送一笔交易，将函数以及相关参数放到交易的data中，也就是调用Client::submitTransaction()这个函数，返回值是h256类型，为交易的hash值，也就是交易的id。如果此笔交易在区块链上得到确认，则智能合约中的函数会被执行，函数中的事件会被触发，事件触发的结果记录在交易的日志中。那么我们去哪里找交易的日志呢？当一笔交易得到确认，我们可以根据交易id去区块链上找到该笔交易的收据(receipt)，receipt中记录交易的执行情况。 执行以下代码可以得到交易收据 1toJson(m_pClient-&gt;localisedTransactionReceipt(h)).toStyledString(); 其中m_pClient是dev::eth::Client类实例，h是交易id。我们执行inc()后，得到的收据内容为 123456789101112131415161718192021222324252627282930{ \"blockHash\" : \"0x862b329c8f5e8310ed5cc6decc18ccc61a96c984aeb3003627abdd9789bd73d9\", \"blockNumber\" : 798, \"contractAddress\" : \"0x46f74069282ce80249112a50c5fdea621436c2e7\", \"cumulativeGasUsed\" : \"0x85ba\", \"from\" : \"0x8fc41de977db1d49cff206ad8b25605e2b63e56e\", \"gasUsed\" : \"0x85ba\", \"logs\" : [ { \"address\" : \"0x59a1181c37245f8b4d7c7a5cec19d22dd5da4331\", \"blockHash\" : \"0x862b329c8f5e8310ed5cc6decc18ccc61a96c984aeb3003627abdd9789bd73d9\", \"blockNumber\" : 798, \"data\" : \"0x00000000000000000000000000000000000000000000000000000000000000460000000000000000000000000000000000000000000000000000000000000015\", \"logIndex\" : 0, \"polarity\" : false, \"topics\" : [ \"0x9b44895fef8929cca514f54bb4c52d35b5f403b960a39478ed7f4408e46eb69e\", \"0x0000000000000000000000000000000000000000000000000000000000000001\" ], \"transactionHash\" : \"0xc5659816ee1239f48cba7d99ea7defeb7b927dff8a9d074f618aa308fb1e9eb4\", \"transactionIndex\" : 0, \"type\" : \"mined\" } ], \"logsBloom\" : \"0x00000000000000000000000000000000000000000000000000000000000000000040000000000000000000000000000000000000000000000010000000040000000000000800000000000000000000000000000000040000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000004000000000008000000000000000000000000000000000000000000000000000040000020000000000000000000000000000000000000000000000000000000000000\", \"stateRoot\" : \"0x2ff5b94c86fb021d6c354f827278ec48bd037a9b3981253f383717fe8f022eda\", \"to\" : \"0x59a1181c37245f8b4d7c7a5cec19d22dd5da4331\", \"transactionHash\" : \"0xc5659816ee1239f48cba7d99ea7defeb7b927dff8a9d074f618aa308fb1e9eb4\", \"transactionIndex\" : 0} 我们要从日志从寻找需要的东西，因此我们关注logs这部分内容。再看topics，这是一个数组，第一行的内容应该为事件名称的hash值，我们来计算一下： 12auto sh = dev::sha3(\"Incremented(bool,uint256,uint256)\");std::cout &lt;&lt; \"0x\" &lt;&lt; sh.hex() &lt;&lt; std::endl; 结果正是0x9b44895fef8929cca514f54bb4c52d35b5f403b960a39478ed7f4408e46eb69e，因此我们就知道这个事件得到了触发。再来看这个事件的参数，第一个参数是x % 2 == 0的值，应该true, 也就是1，正是topics中第二行的值，注意到合约代码中Incremented第一个参数是indexed的，也就是这个标志的参数都会记录在topics的第2-n行中。那么没有这个标志的参数在哪呢？注意到上面还有个data，内容为0x00000000000000000000000000000000000000000000000000000000000000460000000000000000000000000000000000000000000000000000000000000015，这个可以分为两部分：0x0000000000000000000000000000000000000000000000000000000000000046和0x0000000000000000000000000000000000000000000000000000000000000015，正是后面两个参数x和y的值，因此通过解析交易收据receipt，我们就能够得到事件触发的完整信息，也就是能够监听这个事件了。","link":"/2019/07/11/从以太坊交易日志中监听智能合约事件event/"},{"title":"以太坊C++源码解析（三）p2p(1)","text":"整个以太坊p2p代码分为两部分，一部分是基于UDP的节点发现协议，另一部分是基于TCP的传输协议，我们先来看第一部分。这部分主要代码在libp2p\\NodeTable.h文件中。 节点发现协议是采用了类kademlia协议(kademlia-like protocol)，关于kademlia协议可以参看wiki:kademlia我们先来看看NodeTable中整体的流程图：涉及到节点发现协议的四种类型数据包： FindNode Neighbours Ping Pong #doDiscoveryNodeTable类是包含在Host类中的，Host类处理p2p模块的一个接口类，后面会谈到。我们先看NodeTable类的构造函数，里面有这段代码： 12m_socketPointer-&gt;connect();doDiscovery(); 其中第一行的connnect()函数名称有点误导，其实是socket绑定本地端口（默认端口UDP30303），并开始接收外面的数据包。第二行的doDiscovery()函数比较重要，我们来看实现代码： 12345678m_timers.schedule(c_bucketRefresh.count(), [this](boost::system::error_code const&amp; _ec){ // ... NodeID randNodeId; crypto::Nonce::get().ref().copyTo(randNodeId.ref().cropped(0, h256::size)); crypto::Nonce::get().ref().copyTo(randNodeId.ref().cropped(h256::size, h256::size)); doDiscover(randNodeId);}); 无关的代码已省略。可以看到这个函数其实是启动了一个定时器，每隔c_bucketRefresh时间执行一个lambda函数，这个lambda函数产生了一个随机节点，并调用了doDiscover()函数。c_bucketRefresh定义： 1std::chrono::milliseconds const c_bucketRefresh = std::chrono::milliseconds(7200); 得出结论，这个函数就是每隔7200ms刷新一次k桶，也就是产生一个随机节点，并调用doDiscover()。 #doDiscover我们再来看看doDiscover()函数的实现： 1234567891011121314151617181920if (_round == s_maxSteps){ LOG(m_logger) &lt;&lt; \"Terminating discover after \" &lt;&lt; _round &lt;&lt; \" rounds.\"; doDiscovery(); return;}auto nearest = nearestNodeEntries(_node);for (unsigned i = 0; i &lt; nearest.size() &amp;&amp; tried.size() &lt; s_alpha; i++){ auto r = nearest[i]; FindNode p(r-&gt;endpoint, _node); p.sign(m_secret); m_socketPointer-&gt;send(p);}m_timers.schedule(c_reqTimeout.count() * 2, [this, _node, _round, _tried](boost::system::error_code const&amp; _ec){ doDiscover(_node, _round + 1, _tried);}); 注：这里的代码已经经过简化，省略了部分不影响理解流程的代码。这部分代码可以分成三段，第一段和第三段代码都是用来做循环用的，并产生一个定时器，保证每隔c_reqTimeout.count() * 2时间间隔会调用一次doDiscover()，并且保证调用次数不超过s_maxSteps。 这两个常量定义如下： 12std::chrono::milliseconds const c_reqTimeout = std::chrono::milliseconds(300);static unsigned const s_maxSteps = boost::static_log2&lt;s_bits&gt;::value; // 值为8 第二段代码比较重要，这里涉及到了一个重要的函数nearestNodeEntries()，根据字面意思是取最近的节点列表，并向这些节点发送FindNode消息。 #nearestNodeEntriesnearestNodeEntries()函数代码： 123456789101112131415vector&lt;shared_ptr&lt;NodeEntry&gt;&gt; NodeTable::nearestNodeEntries(NodeID _target){ // .. map&lt;unsigned, list&lt;shared_ptr&lt;NodeEntry&gt;&gt;&gt; found; // ... vector&lt;shared_ptr&lt;NodeEntry&gt;&gt; ret; for (auto&amp; nodes: found) for (auto const&amp; n: nodes.second) if (ret.size() &lt; s_bucketSize &amp;&amp; !!n-&gt;endpoint &amp;&amp; n-&gt;endpoint.isAllowed()) ret.push_back(n); return ret;} 同样，为了避免贴大段代码影响读者的信息，我这里做了简化，只贴出重要代码。其实这段代码就是从K桶里把节点取出来，然后按距离从小到大排序，返回序列的前s_bucketSize也就是16个节点。这里巧妙的使用了std::map，并将距离作为key，我们都知道std::map是采用红黑树实现，节点默认会按key从小到大排列，因此把节点放到这个map里就自动排序了，免去了手动排序的过程。这里需要注意的是距离是逻辑上的距离，并无实际意义，只是一种节点的筛选方式，我们可以看下距离的计算方式： 1static int distance(NodeID const&amp; _a, NodeID const&amp; _b) { u256 d = sha3(_a) ^ sha3(_b); unsigned ret; for (ret = 0; d &gt;&gt;= 1; ++ret) {}; return ret; } 可以看到这个距离只是两个节点hash做异或，然后计算二进制最高位为1的位的位数。","link":"/2019/06/21/以太坊C-源码解析（三）p2p-1/"},{"title":"以太坊C++源码解析（九）区块头","text":"区块头定义位于libethcore\\BlockHeader.h文件中，是一个非常简单的类，我们来看看它包含哪些重要数据： h256 m_parentHash父区块的hash值，区块与区块之间的连接点 h256 m_sha3Uncles叔区块的hash值 h256 m_stateRoot区块状态树根的hash值 h256 m_transactionsRoot区块内交易树根的hash值 h256 m_receiptsRoot区块内交易收据树根的hash值 int64_t m_number区块高度 u256 m_gasLimit区块中交易的gas总数的上限，由挖矿者设定 u256 m_gasUsed区块中所有交易所用的gas总和，不能超过m_gasLimit Address m_author挖矿者的地址 u256 m_difficulty挖矿难度 关于Merkle Patricia Trie的说明详见：明明白白以太坊Merkle Patricia Trie","link":"/2019/07/04/以太坊C-源码解析（九）区块头/"},{"title":"以太坊C++源码解析（七）交易","text":"以太坊交易类是Transaction，但是这个类几乎没有什么代码，主要代码都在父类TransactionBase中，因此这个类是我们研究的重点。 交易的主要数据TransactionBase类位于libethcore\\TransactionBase.h/cpp中，里面有几个重要的成员： u256 m_nonce;这个是交易的nonce，整数，记录交易发送者的发送次数，从0开始，每发送一次nonce加1，主要是用来防止重放攻击的。 u256 m_value;交易的以太币数量，单位为wei，注意这个值可以为0。 Address m_receiveAddress;交易接收者的以太坊地址 u256 m_gasPrice;发送者愿意支付的gas price，默认为20,000,000,000wei，也就是20Gwei。这个值越大，交易被确认的速度越快。 u256 m_gas;发送者愿意支付的gas值，如果为普通交易，gas值固定为21000，如果是智能合约交易，则gas值大于21000。这个值实际上是gas limit，值必须大于等于实际消耗的gas，小于的话会直接被区块链拒绝，大于没有关系，因为交易完成后多出来的钱会退回发送者账户。交易费=m_gas * m_gasPrice。 bytes m_data;这个是创建智能合约交易时附带的交易编码，对于普通交易这个值为空。 boost::optional m_vrs;交易的签名 以上是一个交易必须的成员，有人可能会注意到没有发送者的信息，实际上发送者信息隐藏在m_vrs中，m_vrs可以反推出发送者的公钥，从而得到发送者地址。 交易的分类 普通交易普通交易是用来交易以太币的，m_gas值为21000，m_data值为空，m_receiveAddress值不为空，m_value值通常不为0 智能合约交易智能合约交易又分为两种a. 创建智能合约交易这个交易用来创建一个智能合约，m_data值不为空，m_receiveAddress为空，m_value为0b. 普通智能合约交易这个通常用来做代币交易，m_data值不为空，m_receiveAddress为智能合约地址。交易的签名一个交易被发出前必须由发送者用自身的私钥进行签名。 这里因为EIP155的存在，情况又有点复杂。 关于EIP155大家可以参考eip-155.md简单说就是在EIP155之前，交易签名的内容包括m_nonce，m_value，m_receiveAddress，m_gasPrice，m_gas和m_data这六项，EIP155之后，签名内容增加了m_vrs，其中v值设为1，r和s值设为0 在TransactionBase类中有一个成员int m_chainId = -4;来区分是否采用EIP155，-4表示不采用，1表示采用。我们来看具体代码： 1234567void TransactionBase::sign(Secret const&amp; _priv){ auto sig = dev::sign(_priv, sha3(WithoutSignature)); SignatureStruct sigStruct = *(SignatureStruct const*)&amp;sig; if (sigStruct.isValid()) m_vrs = sigStruct;} 这是创建交易时候的代码，Secret const&amp; _priv为发送者的私钥，最重要的是这句： 1auto sig = dev::sign(_priv, sha3(WithoutSignature)); 这句代码又可以分为两句： sha3(WithoutSignature)用来对交易数据进行hash运算，这里的交易数据就要区分EIP155了，如果是非EIP155就需要对六项数据做hash，否则需要对九项数据做hash。 dev::sign(_priv, hash值)对hash结果做签名我们先来看看hash运算：12345678910111213h256 TransactionBase::sha3(IncludeSignature _sig) const{ if (_sig == WithSignature &amp;&amp; m_hashWith) return m_hashWith; RLPStream s; streamRLP(s, _sig, m_chainId &gt; 0 &amp;&amp; _sig == WithoutSignature); auto ret = dev::sha3(s.out()); if (_sig == WithSignature) m_hashWith = ret; return ret;} 可见这里是对交易数据先编码成RLP，然后再用dev::sha3()做运算。关键在streamRLP()函数中： 123456789101112131415161718192021222324252627282930void TransactionBase::streamRLP(RLPStream&amp; _s, IncludeSignature _sig, bool _forEip155hash) const{ if (m_type == NullTransaction) return; _s.appendList((_sig || _forEip155hash ? 3 : 0) + 6); _s &lt;&lt; m_nonce &lt;&lt; m_gasPrice &lt;&lt; m_gas; if (m_type == MessageCall) _s &lt;&lt; m_receiveAddress; else _s &lt;&lt; \"\"; _s &lt;&lt; m_value &lt;&lt; m_data; if (_sig) { if (!m_vrs) BOOST_THROW_EXCEPTION(TransactionIsUnsigned()); if (hasZeroSignature()) _s &lt;&lt; m_chainId; else { int const vOffset = m_chainId * 2 + 35; _s &lt;&lt; (m_vrs-&gt;v + vOffset); } _s &lt;&lt; (u256)m_vrs-&gt;r &lt;&lt; (u256)m_vrs-&gt;s; } else if (_forEip155hash) _s &lt;&lt; m_chainId &lt;&lt; 0 &lt;&lt; 0;} 这部分代码比较简单，m_type为MessageCall表示非创建合约交易，这时的m_receiveAddress值是有效的。_forEip155hash表示是否采用EIP155，m_chainId默认为-4，所以不采用，因此这个stream里编码的值只有上面那六项。dev::sign()签名算法就不贴出来了，有兴趣的可以自己去看，都是一些算法。","link":"/2019/07/04/以太坊C-源码解析（七）交易/"},{"title":"以太坊C++源码解析（一）Worker类","text":"在ethereum项目中Worker类是许多类的基类，子类们继承Worker类严格来说并不是is-a的关系，而是复用Worker类中的代码，因此可以说Worker类是一份公用代码类，那么是什么代码这么重要呢？ 在Worker类中我们直接来看其成员，可以看到有两个重要的成员变量： 12std::unique_ptr&lt;std::thread&gt; m_work;mutable std::condition_variable m_state_notifier; 看到这里经验丰富的程序员们应该就能想到这个是经典的生产消费者队列的C++11实现方式，还不了解生产消费者队列的同学可以暂停一下，先搜索一下相关知识再继续。然后我们再来看两个重要的成员函数： 12void startWorking();void stopWorking(); 这个其实就是启动和停止m_work这个线程了。在startWorking()函数内部我们能看到线程的初始化过程，线程函数体用的是lambda表达式，其中最重要的一段我列出来： 12345678910try{ startedWorking(); workLoop(); doneWorking();}catch (std::exception const&amp; _e){ cwarn &lt;&lt; \"Exception thrown in Worker thread: \" &lt;&lt; _e.what();} 这个线程最重要的是执行了这三个操作，startedWorking()用于workLoop()前的准备工作,doneWorking()用于workLoop()后的收尾工资，workLoop()内部用一个循环调用了doWork()来做实际的工作： 123456789void Worker::workLoop(){ while (m_state == WorkerState::Started) { if (m_idleWaitMs) this_thread::sleep_for(chrono::milliseconds(m_idleWaitMs)); doWork(); }} 我们再来看这几个函数的定义： 1234virtual void startedWorking() {}virtual void doWork() {}virtual void workLoop();virtual void doneWorking() {} 可以看到除了workLoop()有一个默认的实现外，其他函数体都是空的，子类们通过重新实现这几个函数来实现具体的功能，后面我们会看到这些子类们是怎么做的。","link":"/2019/06/18/以太坊C-源码解析（一）Worker类/"},{"title":"以太坊C++源码解析（三）p2p(5)","text":"Session类我们终于到了关键地方，Session类代码位于libp2p\\Session.h中 ，这个类代表的是socket通讯中的连接，这才是真正处理通讯协议的地方！ 在上一节中Host::startPeerSession()函数将EthereumPeer类对象放入了Session类对象，具体在哪里呢？在这里： 1std::map&lt;CapDesc, std::shared_ptr&lt;Capability&gt;&gt; m_capabilities; 这个map中存放了这个连接的消息处理器。我们再来看Session类是怎么工作的，首先从Session::start()看起。 12345void Session::start(){ ping(); doRead();} 这个函数很简单，连接建立起来以后，先ping一下对方，也就是先给对方发一个ping的包，然后等待对方回应。ping()函数没什么说的，我们来看doRead()这个函数： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768void Session::doRead(){ // ... m_data.resize(h256::size); ba::async_read(m_socket-&gt;ref(), boost::asio::buffer(m_data, h256::size), [this, self](boost::system::error_code ec, std::size_t length) { // ... if (!checkRead(h256::size, ec, length)) return; else if (!m_io-&gt;authAndDecryptHeader(bytesRef(m_data.data(), length))) { cnetlog &lt;&lt; \"header decrypt failed\"; drop(BadProtocol); // todo: better error return; } uint16_t hProtocolId; uint32_t hLength; uint8_t hPadding; try { RLPXFrameInfo header(bytesConstRef(m_data.data(), length)); hProtocolId = header.protocolId; hLength = header.length; hPadding = header.padding; } catch (std::exception const&amp; _e) { // ... return; } /// read padded frame and mac auto tlen = hLength + hPadding + h128::size; m_data.resize(tlen); ba::async_read(m_socket-&gt;ref(), boost::asio::buffer(m_data, tlen), [this, self, hLength, hProtocolId, tlen]( boost::system::error_code ec, std::size_t length) { // ... if (!checkRead(tlen, ec, length)) return; else if (!m_io-&gt;authAndDecryptFrame(bytesRef(m_data.data(), tlen))) { cnetlog &lt;&lt; \"frame decrypt failed\"; drop(BadProtocol); // todo: better error return; } bytesConstRef frame(m_data.data(), hLength); if (!checkPacket(frame)) { // ... return; } else { auto packetType = (PacketType)RLP(frame.cropped(0, 1)).toInt&lt;unsigned&gt;(); RLP r(frame.cropped(1)); bool ok = readPacket(hProtocolId, packetType, r); if (!ok) cnetlog &lt;&lt; \"Couldn't interpret packet. \" &lt;&lt; RLP(r); } doRead(); }); });} 这段代码看起来比较长，可别被它吓到了，其实很简单，可以分成几步来看： 初始化接收缓冲区 1m_data.resize(h256::size); 收包 12ba::async_read(m_socket-&gt;ref(), boost::asio::buffer(m_data, h256::size), [this, self](boost::system::error_code ec, std::size_t length) 收到包后检查包 12345678if (!checkRead(h256::size, ec, length)) return;else if (!m_io-&gt;authAndDecryptHeader(bytesRef(m_data.data(), length))){ cnetlog &lt;&lt; \"header decrypt failed\"; drop(BadProtocol); // todo: better error return;} 没问题的话解析包头 1234RLPXFrameInfo header(bytesConstRef(m_data.data(), length));hProtocolId = header.protocolId;hLength = header.length;hPadding = header.padding; hLength表示包头后续数据包大小，hPadding表示后续数据包与包头间的偏移。 接收后续数据包 1234auto tlen = hLength + hPadding + h128::size;m_data.resize(tlen);ba::async_read(m_socket-&gt;ref(), boost::asio::buffer(m_data, tlen), [this, self, hLength, hProtocolId, tlen] 可以看到后续数据包大小的计算方法。 再次检查数据包这个和第三步是一样的 解析数据包 1234bytesConstRef frame(m_data.data(), hLength);auto packetType = (PacketType)RLP(frame.cropped(0, 1)).toInt&lt;unsigned&gt;();RLP r(frame.cropped(1));bool ok = readPacket(hProtocolId, packetType, r); 数据包中的内容放到了RLP类对象中，然后调用readPacket()进行具体分析。 继续收包 1doRead(); Session::readPacket()这里就是具体处理网络数据包的地方了，代码也不多： 123456789101112131415161718192021bool Session::readPacket(uint16_t _capId, PacketType _t, RLP const&amp; _r){ // ... try { if (_capId == 0 &amp;&amp; _t &lt; UserPacket) return interpret(_t, _r); for (auto const&amp; i: m_capabilities) if (_t &gt;= (int)i.second-&gt;m_idOffset &amp;&amp; _t - i.second-&gt;m_idOffset &lt; i.second-&gt;hostCapability()-&gt;messageCount()) return i.second-&gt;enabled() ? i.second-&gt;interpret(_t - i.second-&gt;m_idOffset, _r) : true; return false; } catch (std::exception const&amp; _e) { // ... return true; } return true;} 其中的_t类型是PacketType，其实就是上一节所说的消息偏移，消息偏移小于UserPacket的包由Session类自身处理，剩下的包交给m_capabilities中的消息处理器，每个消息处理器处理各自能力范围内的消息。最后看下Session::interpret()函数的实现： 1234567891011121314151617181920212223242526272829bool Session::interpret(PacketType _t, RLP const&amp; _r){ switch (_t) { case DisconnectPacket: { // ... break; } case PingPacket: { cnetdetails &lt;&lt; \"Ping \" &lt;&lt; m_info.id; RLPStream s; sealAndSend(prep(s, PongPacket)); break; } case PongPacket: DEV_GUARDED(x_info) { m_info.lastPing = std::chrono::steady_clock::now() - m_ping; cnetdetails &lt;&lt; \"Latency: \" &lt;&lt; chrono::duration_cast&lt;chrono::milliseconds&gt;(m_info.lastPing).count() &lt;&lt; \" ms\"; } break; // ... } return true;} 可以看到这里真正有用的地方只是收到ping包之后回复一个pong包，和前面的握手流程类似。收到pong包以后也只是更新了时间，没有其他内容了，那第一个真正有意义的包是谁来发起的呢？这个需要从Session类外去寻找答案了。","link":"/2019/07/04/以太坊C-源码解析（三）p2p-5/"},{"title":"以太坊C++源码解析（二）大数据类型","text":"我们在C++中常用的表示整形的类型有int, long, unsigned long, int64_t等等，这些类型的长度为32位，64位，一般的情况下就能满足我们的需要了，但是在以太坊里这样的精度类型就显得捉襟见肘了，比如以太坊中常用的货币单位为Wei，而以太币1Ether=10的18次方Wei，这是一个非常大的数，普通的数据类型显然不能用了，我们需要更大的数。 #boost::multiprecision好在C++的boost库里提供了这样的数据类型，它们就存在于boost::multiprecision命名空间中，大家可以在这个网页看到定义：https://www.boost.org/doc/libs/1_65_1/libs/multiprecision/doc/html/boost_multiprecision/tut/ints/cpp_int.html可以看到里面定义了uint128_t，uint256_t，uint512_t甚至uint1024_t。在以太坊ethereum代码中也使用了类似的定义，不过名字不同，采用的u128表示128位无符号数，u256表示256位无符号数，以此类推，具体定义在libdevcore\\Common.h文件中。需要注意的是这种数据类型与字符串类型的转换，因为我们经常需要输出这种数值，转换位字符串会比较方便，这种类型提供了转换为std::string的方法，那就是str()函数，比如： 12u256 value = *******;std::string strValue = value.str(); u128,u256等类型在以太坊代码中使用非常频繁，比如区块头BlockHeader.h中定义了： 123u256 m_gasLimit;u256 m_gasUsed;u256 m_difficulty; m_gasLimit表示gas最大值，m_gasUsed表示所使用的gas，m_difficulty表示挖矿难度。 #FixedHash类FxedHash类是一个模板类，定义于libdevcore\\FixedHash.h中，我们查看这个类定义，可以看到它就只有一个数据成员： 1std::array&lt;byte, N&gt; m_data; 所以这就是一个封装的字节数组类，里面重载了==,!=,&gt;=等符号，还提供了一个成员hex()用于将字节数组转化为字符串数组： 1std::string hex(); 为了方便使用，该文件中还定义了一些别名，比如： 12345using h520 = FixedHash&lt;65&gt;;using h512 = FixedHash&lt;64&gt;;using h256 = FixedHash&lt;32&gt;;using h160 = FixedHash&lt;20&gt;;using h128 = FixedHash&lt;16&gt;; h256表示32个字节大小的字节数组，其他以此类推。FixedHash类在以太坊中也经常用到，通常来表示hash值，我们还是以BlockHeader为例： 12345h256 m_parentHash;h256 m_sha3Uncles;h256 m_stateRoot;h256 m_transactionsRoot;h256 m_receiptsRoot; m_parentHash表示父块的hash值，m_sha3Uncles表示叔块的hash值，m_stateRoot表示state树根hash，m_transactionsRoot表示交易树根hash，m_receiptsRoot表示收据树根hash。","link":"/2019/06/21/以太坊C-源码解析（二）大数据类型/"},{"title":"以太坊C++源码解析（三）p2p(2)","text":"K桶的实现这里借用一下别人的图：可以看到这个就是一个二维数组，可以简单定义为：int bucket[256][16]其中第一维是从0-255表示距离，第二维记录16个节点。 在代码中实际的K桶定义是： 1std::array&lt;NodeBucket, s_bins&gt; m_state; 这个定义等同于 1NodeBucket[s_bins] m_state; 其中s_bins值为255，根据上面的图，s_bins应该是256，为什么是255呢？这里其实是把距离为0的那些节点排除掉了，所以为255。再来看NodeBucket的定义： 12345struct NodeBucket{ unsigned distance; std::list&lt;std::weak_ptr&lt;NodeEntry&gt;&gt; nodes;}; 这里的nodes就是实际存放在K桶里的节点了，在这里还看不出来nodes数组的大小，不过在实际添加节点的时候会有大小判断： 123456if (nodes.size() &lt; s_bucketSize){ // ... nodes.push_back(newNode); // ...} s_bucketSize的值正是16. #noteActiveNodenoteActiveNode这个函数在每收到一个UDP包都会被调用，其主要实现代码为： 1234567891011121314151617181920212223242526272829303132333435NodeBucket&amp; s = bucket_UNSAFE(newNode.get());auto&amp; nodes = s.nodes;// check if the node is already in the bucketauto it = std::find(nodes.begin(), nodes.end(), newNode);if (it != nodes.end()){ // if it was in the bucket, move it to the last position nodes.splice(nodes.end(), nodes, it);}else{ if (nodes.size() &lt; s_bucketSize) { // if it was not there, just add it as a most recently seen node // (i.e. to the end of the list) nodes.push_back(newNode); if (m_nodeEventHandler) m_nodeEventHandler-&gt;appendEvent(newNode-&gt;id, NodeEntryAdded); } else { // if bucket is full, start eviction process for the least recently seen node nodeToEvict = nodes.front().lock(); // It could have been replaced in addNode(), then weak_ptr is expired. // If so, just add a new one instead of expired if (!nodeToEvict) { nodes.pop_front(); nodes.push_back(newNode); if (m_nodeEventHandler) m_nodeEventHandler-&gt;appendEvent(newNode-&gt;id, NodeEntryAdded); } }} 这部分是目前我贴出来的最长的代码了，代码虽然长一点，但是可读性非常好，而且有详细的注释。这部分涉及到K桶的操作，收到一个节点后判断是否已经在K桶中了，如果在的话就移动它到nodes的末尾，如果不存在就放到K桶中，这里需要重点注意两行代码： 12if (m_nodeEventHandler) m_nodeEventHandler-&gt;appendEvent(newNode-&gt;id, NodeEntryAdded); 这段代码在节点被放到K桶中时会被调用，这两句非常重要，作用后面再说。 #预设节点这里还有个问题，不知道读者朋友有没有注意到，那就是虽然有节点发现协议来源源不断地发现新节点，但是初始化的时候是只有本节点一个节点的，我从哪里去获得其他节点的IP呢？还记得上一节的nearestNodeEntries()这个函数吗？这个函数是从K桶中取得节点，按距离从小到大排列，然后向这些节点发送FindNode消息的，但是初始情况下K桶是空的，我们要向哪发消息呢？巧妇也难为无米之炊啊，因此这里必然隐藏了一个特殊的绿色通道，用来直接放入初始节点的。这个绿色通道就是NodeTable::addNode()函数，这个函数在多处出现，大部分情况下为正常调用，但是注意到这个函数在Host::addNodeToNodeTable()函数里调用了，我们再来顺藤摸瓜，看看Host::addNodeToNodeTable()在哪里调用，也有多个地方，但是值得注意的是在Host::requirePeer()里的调用。因为这个函数在aleth\\main.cpp里被调用到了，我把调用的地方贴出来： 12for (auto const&amp; i: Host::pocHosts()) web3.requirePeer(i.first, i.second); 这段代码看起来就是在添加一些节点，web3为dev::WebThreeDirect类，而 web3.requirePeer()会调用Host::requirePeer()，至此这些预设节点被添加到NodeTable中，相当于给机器一个初始的力，于是机器开始正常运转起来。有兴趣的读者还可以去Host::pocHosts()看看是哪些初始节点。 #添加节点到传输网络以太坊的P2P模块其实分为两部分，第一部分就是目前说到的UDP节点发现协议，另外一部分是TCP的节点间数据传输协议，这两部分之间是通过什么交互的呢？也就是节点是怎么从第一部分被发现到第二部分和本节点间传输数据呢？其实前面这两句看起来不起眼的代码就是连接两部分之间的桥梁。NodeTable类内置一个事件处理器： 1std::unique_ptr&lt;NodeTableEventHandler&gt; m_nodeEventHandler; NodeTableEventHandler类通过appendEvent()来添加事件，并通过processEvents()来处理每个事件，那么事件是怎么处理的呢？但是processEvent()事件处理函数是一个纯虚函数： 1virtual void processEvent(NodeID const&amp; _n, NodeTableEventType const&amp; _e) = 0; 因此要到它的子类去找，可以看到libp2p\\Host.h文件中定义了子类：HostNodeTableHandler，也实现了processEvent()函数： 1234void HostNodeTableHandler::processEvent(NodeID const&amp; _n, NodeTableEventType const&amp; _e) { m_host.onNodeTableEvent(_n, _e);} 这里又调用了Host::onNodeTableEvent()函数。 1234567891011121314151617181920void Host::onNodeTableEvent(NodeID const&amp; _n, NodeTableEventType const&amp; _e){ if (_e == NodeEntryAdded) { LOG(m_logger) &lt;&lt; \"p2p.host.nodeTable.events.nodeEntryAdded \" &lt;&lt; _n; if (Node n = nodeFromNodeTable(_n)) { shared_ptr&lt;Peer&gt; p; // ... if (peerSlotsAvailable(Egress)) connect(p); } } else if (_e == NodeEntryDropped) { // ... if (m_peers.count(_n) &amp;&amp; m_peers[_n]-&gt;peerType == PeerType::Optional) m_peers.erase(_n); }} 这里同样精简了代码，值得注意的是connect(p);这一句，从字面上看是连接节点，实际代码是通过boost::asio库实现了底层网络传输。现在事情已经比较清楚了，那么NodeTableEventHandler::processEvent()函数是由谁来调用的呢？其实是Host里的一个定时器调用的，有兴趣的读者可以去看Host::run()函数，其实就是Host类与NodeTable类之间的相互调用。","link":"/2019/07/02/以太坊C-源码解析（三）p2p-2/"},{"title":"以太坊C++源码解析（三）p2p(4)","text":"从Host类到Session类上一节我们跟踪到了Host::startPeerSession()函数里，现在我们来深入这个函数看个究竟。 123456789101112131415161718192021222324252627282930313233void Host::startPeerSession(Public const&amp; _id, RLP const&amp; _rlp, unique_ptr&lt;RLPXFrameCoder&gt;&amp;&amp; _io, std::shared_ptr&lt;RLPXSocket&gt; const&amp; _s){ // session maybe ingress or egress so m_peers and node table entries may not exist shared_ptr&lt;Peer&gt; p; // ... // create session so disconnects are managed shared_ptr&lt;SessionFace&gt; ps = make_shared&lt;Session&gt;(this, move(_io), _s, p, PeerSessionInfo({_id, clientVersion, p-&gt;endpoint.address.to_string(), listenPort, chrono::steady_clock::duration(), _rlp[2].toSet&lt;CapDesc&gt;(), 0, map&lt;string, string&gt;(), protocolVersion})); // ... { RecursiveGuard l(x_sessions); // ... unsigned offset = (unsigned)UserPacket; // todo: mutex Session::m_capabilities and move for(:caps) out of mutex. for (auto const&amp; i: caps) { auto pcap = m_capabilities[i]; if (!pcap) return ps-&gt;disconnect(IncompatibleProtocol); pcap-&gt;newPeerCapability(ps, offset, i); // 重要！ offset += pcap-&gt;messageCount(); } ps-&gt;start(); m_sessions[_id] = ps; } LOG(m_logger) &lt;&lt; \"p2p.host.peer.register \" &lt;&lt; _id;} 可以看到这个函数里先是创建了一个Session类，然后对m_capabilities的成员调用newPeerCapability()来为每一个session创建一个capability，也就是消息处理器，最后调用session类的start()函数。看到这里可能读者会一头雾水，不知道这里是做了什么处理，不用急，我们还是先从m_capabilities谈起。m_capabilities定义在Host类中： 1std::map&lt;CapDesc, std::shared_ptr&lt;HostCapabilityFace&gt;&gt; m_capabilities; CapDesc定义为： 1using CapDesc = std::pair&lt;std::string, u256&gt;; HostCapabilityFace是一个虚基类，最重要的成员有两个： 12345678910class HostCapabilityFace{public: // ... virtual unsigned messageCount() const = 0; virtual std::shared_ptr&lt;Capability&gt; newPeerCapability( std::shared_ptr&lt;SessionFace&gt; const&amp; _s, unsigned _idOffset, CapDesc const&amp; _cap) = 0; // ...}; 这两个函数正是在Host::startPeerSession()函数中被调用的那两个！目前我们还不清楚这两个函数的具体功能，我们需要去找HostCapabilityFace类的子类，看看它们的实现。为了找子类，我们需要找m_capabilities在哪里插入数据，发现是在Host::registerCapability()函数中 12345678910void Host::registerCapability(std::shared_ptr&lt;HostCapabilityFace&gt; const&amp; _cap){ registerCapability(_cap, _cap-&gt;name(), _cap-&gt;version());}void Host::registerCapability( std::shared_ptr&lt;HostCapabilityFace&gt; const&amp; _cap, std::string const&amp; _name, u256 const&amp; _version){ m_capabilities[std::make_pair(_name, _version)] = _cap;} 再找Host::registerCapability()在哪里被调用，找到libethereum\\client.cpp里的Client::init()，里面有一段代码： 123auto ethHostCapability = make_shared&lt;EthereumHost&gt;(_extNet, bc(), m_stateDB, m_tq, m_bq, _networkId);_extNet.registerCapability(ethHostCapability); _extNet就是Host对象，原来HostCapabilityFace类的子类是EthereumHost类。EthereumHost类也是一个非常重要的类，我们后面再谈，这个类的定义有点意思，我们先来看看： 1class EthereumHost: public p2p::HostCapability&lt;EthereumPeer&gt;, Worker 可以看到这个类除了从Worker类继承外，还继承了 p2p::HostCapability&lt;EthereumPeer&gt;类。一下子又引入了两个新类。一个一个来，我们先来看看 p2p::HostCapability类定义： 1234567891011121314151617template&lt;class PeerCap&gt;class HostCapability: public HostCapabilityFace{public: // ... unsigned messageCount() const override { return PeerCap::messageCount(); } std::shared_ptr&lt;Capability&gt; newPeerCapability( std::shared_ptr&lt;SessionFace&gt; const&amp; _s, unsigned _idOffset, CapDesc const&amp; _cap) override { auto p = std::make_shared&lt;PeerCap&gt;(_s, this, _idOffset, _cap); _s-&gt;registerCapability(_cap, p); return p; } // ...}; 原来HostCapability&lt;&gt;类才是HostCapabilityFace类的直接子类，EthereumHost类是HostCapabilityFace类的孙子类。messageCount()和newPeerCapability()这两个函数在HostCapability&lt;&gt;类里有一份实现。而且这个类是一个模板类，messageCount()只是调用了模板参数PeerCap的messageCount()函数。newPeerCapability()函数只是创建一个PeerCap对象，并调用其registerCapability()函数。对于EthereumHost类，模板参数PeerCap就是EthereumPeer，这点可以从EthereumHost类定义中得到，因此在EthereumHost类里，这两个函数相当于： 123456789unsigned EthereumHost::messageCount() const override { return EthereumPeer::messageCount(); }std::shared_ptr&lt;Capability&gt; EthereumHost::newPeerCapability( std::shared_ptr&lt;SessionFace&gt; const&amp; _s, unsigned _idOffset, CapDesc const&amp; _cap) override{ auto p = std::make_shared&lt;EthereumPeer&gt;(_s, this, _idOffset, _cap); _s-&gt;registerCapability(_cap, p); return p;} 先来看newPeerCapability这个函数吧，它创建了一个EthereumPeer类对象，并调用SessionFace::registerCapability()注册了该对象，也就是把EthereumPeer类对象放到了Session类对象里，EthereumPeer类是Session消息处理器。实际上EthereumHost类自身对newPeerCapability()函数也有自己的实现，这个实现与父类HostCapability&lt;&gt;的实现稍有不同，这个后面再谈。messageCount()函数简单返回了一个消息数量，这个用来将不同的HostCapabilityFace的消息错开，方便消息分发，每个HostCapabilityFace处理某一段范围内的消息。","link":"/2019/07/02/以太坊C-源码解析（三）p2p-4/"},{"title":"以太坊C++源码解析（五）区块链同步(2)","text":"区块链同步的核心类是BlockChainSync，在继续深入了解同步流程之前，我们还是先来了解一下这个类有哪些重要成员吧。 m_chainStartBlock &amp; m_startingBlock &amp; m_highestBlock这三个分别表示链起始块号，一般是0；需要同步的起始块号；当前所知的最大块号 m_lastImportedBlock &amp; m_lastImportedBlockHash这两个表示当前同步的最新块的块号和块hash值，在同步中我们需要知道当前同步到多少块了就是看m_lastImportedBlock这个值，这是一个重要指标。 m_downloadingHeaders &amp; m_downloadingBodies &amp; m_headerSyncPeers &amp; m_bodySyncPeers这几个定义稍微复杂一些：1234std::unordered_set&lt;unsigned&gt; m_downloadingHeaders; ///&lt; Set of block body numbers being downloadedstd::unordered_set&lt;unsigned&gt; m_downloadingBodies; ///&lt; Set of block header numbers being downloadedstd::map&lt;std::weak_ptr&lt;EthereumPeer&gt;, std::vector&lt;unsigned&gt;, std::owner_less&lt;std::weak_ptr&lt;EthereumPeer&gt;&gt;&gt; m_headerSyncPeers; ///&lt; Peers to m_downloadingSubchain number mapstd::map&lt;std::weak_ptr&lt;EthereumPeer&gt;, std::vector&lt;unsigned&gt;, std::owner_less&lt;std::weak_ptr&lt;EthereumPeer&gt;&gt;&gt; m_bodySyncPeers; ///&lt; Peers to m_downloadingSubchain number map 其中m_downloadingHeaders记录当前正在同步的块头对应的块号；m_downloadingBodies记录单曲正在同步的块体对应的块号；m_headerSyncPeers在m_downloadingHeaders的基础上还记录了peer信息；m_bodySyncPeers在m_downloadingBodies的基础上记录了peer信息。 注意到这里有个模板std::owner_less&lt;&gt;，这个模板是用来表明如何对std::weak_ptr&lt;EthereumPeer&gt;进行排序的，这里有一个owner-base和value-base的概念，在一般情况下owner-base和value-base是相同的，但是在std::shared_ptr和std::weak_ptr使用aliasing constructor(别名构造函数)时这两者不同，需要区分。推荐两篇文件，讲得比较详细：C++ Memory Library - owner_lessWhat is shared_ptr’s aliasing constructor for? 那么同步中记录这四个值有什么用呢？在这里是用来做校验的。因为BlockChainSync类从HasInvariants类继承而来，因此继承了一个接口： 1virtual bool invariants() const = 0; 可以在BlockChainSync::invariants()中找到答案： 12345678910111213141516bool BlockChainSync::invariants() const{ if (!isSyncing() &amp;&amp; !m_headers.empty()) BOOST_THROW_EXCEPTION(FailedInvariant() &lt;&lt; errinfo_comment(\"Got headers while not syncing\")); if (!isSyncing() &amp;&amp; !m_bodies.empty()) BOOST_THROW_EXCEPTION(FailedInvariant() &lt;&lt; errinfo_comment(\"Got bodies while not syncing\")); if (isSyncing() &amp;&amp; m_host.chain().number() &gt; 0 &amp;&amp; m_haveCommonHeader &amp;&amp; m_lastImportedBlock == 0) BOOST_THROW_EXCEPTION(FailedInvariant() &lt;&lt; errinfo_comment(\"Common block not found\")); if (isSyncing() &amp;&amp; !m_headers.empty() &amp;&amp; m_lastImportedBlock &gt;= m_headers.begin()-&gt;first) BOOST_THROW_EXCEPTION(FailedInvariant() &lt;&lt; errinfo_comment(\"Header is too old\")); if (m_headerSyncPeers.empty() != m_downloadingHeaders.empty()) BOOST_THROW_EXCEPTION(FailedInvariant() &lt;&lt; errinfo_comment(\"Header download map mismatch\")); if (m_bodySyncPeers.empty() != m_downloadingBodies.empty() &amp;&amp; m_downloadingBodies.size() &lt;= m_headerIdToNumber.size()) BOOST_THROW_EXCEPTION(FailedInvariant() &lt;&lt; errinfo_comment(\"Body download map mismatch\")); return true;} 那么在哪里调用这个函数呢？在InvariantChecker::checkInvariants()函数里： 12345678void InvariantChecker::checkInvariants(HasInvariants const* _this, char const* _fn, char const* _file, int _line, bool _pre){ if (!_this-&gt;invariants()) { cwarn &lt;&lt; (_pre ? \"Pre\" : \"Post\") &lt;&lt; \"invariant failed in\" &lt;&lt; _fn &lt;&lt; \"at\" &lt;&lt; _file &lt;&lt; \":\" &lt;&lt; _line; ::boost::exception_detail::throw_exception_(FailedInvariant(), _fn, _file, _line); }} 而这个函数被定义成了两个宏： 1234567#if ETH_DEBUG#define DEV_INVARIANT_CHECK ::dev::InvariantChecker __dev_invariantCheck(this, BOOST_CURRENT_FUNCTION, __FILE__, __LINE__)#define DEV_INVARIANT_CHECK_HERE ::dev::InvariantChecker::checkInvariants(this, BOOST_CURRENT_FUNCTION, __FILE__, __LINE__, true)#else#define DEV_INVARIANT_CHECK (void)0;#define DEV_INVARIANT_CHECK_HERE (void)0;#endif DEV_INVARIANT_CHECK和DEV_INVARIANT_CHECK_HERE这两个宏在代码中多次调用，有兴趣可以去看看源码。 除了BlockChainSync类之外，还有一个重要类BlockQueue类也是从HasInvariants类继承而来，因而也具有check的能力。 m_headers &amp; m_bodies这两个是下载的块头和块体的缓冲区，当块头和块体不属于同一个块，因而无法合并时，被暂存在这里。12std::map&lt;unsigned, std::vector&lt;Header&gt;&gt; m_headers; ///&lt; Downloaded headersstd::map&lt;unsigned, std::vector&lt;bytes&gt;&gt; m_bodies; ///&lt; Downloaded block bodies 这里使用了std::map，key表示m_headers或m_bodies中连续段最低块的块号，value表示m_headers或m_bodies中存在的数据。每个std::vector中保存一个连续段的数据。以m_headers为例，假如有块5，6，7，10，13，15，16，那么在m_headers中存储为：{ {5, {块5，块6，块7} }, {10, {块10} }, {13, {块13} }, {15, {块15，块16} } }，其中5，6，7是一个连续段，存为一个pair，key为5，value为std::vector&lt;Header&gt;{块5，块6，块7}，块10为一个单独不连续块，那么存为一个pair，key为10，value为std::vector&lt;Header&gt;{块10}，以此类推，m_bodies也是一样。为了在这种数据结构中方便查找，插入和删除数据，还专门定义了专有方法，比如haveItem()，findItem()，removeItem()，removeAllStartingWith()和mergeInto()，有兴趣可以自己看下，能更深入理解这种数据结构的操作。m_headers 和 m_bodies构成了整个区块链同步的第一级缓存，存放了刚下载下来未经校验的分离的区块头和区块体。整个区块链同步的数据流程大致如下： m_haveCommonHeader这是一个简简单单的布尔值，默认为false，但是却非常重要，它实际决定了同步块的起点，这里可能会有人问上面不是有个m_lastImportedBlock吗？难道不是每次都是从这里开始同步的吗？理论上是的，但是实际中同步区块链有个回退操作，开始时m_haveCommonHeader值为false，那么回退一个块，从m_haveCommonHeader - 1块开始同步，当m_haveCommonHeader - 1块头下载下来以后，和本地区块链或者BlockQueue中的m_haveCommonHeader - 1块做比较，如果是一样的，那么m_haveCommonHeader值设为true，证明我们之前下载的区块链和当前这个peer上下载的区块是同一条链上的，可以放心向后同步了。如果不一样，那么证明我们的区块链和peer上的区块不是在同一条链上（可能有分叉），这时候需要继续回退，下载m_haveCommonHeader - 2等等，直到m_haveCommonHeader值为true才算回退到头，这个也是区块链同步有时候会停滞的原因之一，尤其是在ropsten测试链中这种情况经常出现。除了开始同步时可能存在回退的情况，在导入块，也就是从一级缓存进入二级缓存BlockQueue时也会做检查，如果出错也可能导致回退。","link":"/2019/07/04/以太坊C-源码解析（五）区块链同步-2/"},{"title":"以太坊C++源码解析（五）区块链同步(6)","text":"除了上面的同步形式外，区块链节点之间还存在另外两种特殊形式的同步，一种是交易同步，也就是当某个节点完成一笔交易后，需要向其他节点广播这个交易，另一种是矿工成功挖到一个区块，也要向其他节点广播这个新的区块。我们来看看这两种同步是怎么进行的。 交易同步交易同步的数据包类型是TransactionsPacket，EthereumPeer收到这个包以后直接就在EthereumPeerObserver里做了处理，并没有转交给BlockChainSync，可能是因为这个处理太简单的缘故，我们也可以从代码中看出来： 123456void onPeerTransactions(std::shared_ptr&lt;EthereumPeer&gt; _peer, RLP const&amp; _r) override{ unsigned itemCount = _r.itemCount(); LOG(m_logger) &lt;&lt; \"Transactions (\" &lt;&lt; dec &lt;&lt; itemCount &lt;&lt; \" entries)\"; m_tq.enqueue(_r, _peer-&gt;id());} 这里的处理就是放到m_tq里，这里的m_tq是TransactionQueue对象，TransactionQueue是一个专门放pending交易的队列，也就是还没有正式进入区块链的“无主”交易待的地方。关于这个类，后续会专门来讲。 新区块同步新区块包的数据类型是NewBlockPacket，这次处理的重任重新回到了BlockChainSync，因此，我们来看看BlockChainSync::onPeerNewBlock的处理吧。这个处理分为两部分，第一部分是常规检查： 12345678910111213141516171819if (_r.itemCount() != 2){ _peer-&gt;disable(\"NewBlock without 2 data fields.\"); return;}BlockHeader info(_r[0][0].data(), HeaderData);auto h = info.hash();DEV_GUARDED(_peer-&gt;x_knownBlocks) _peer-&gt;m_knownBlocks.insert(h);unsigned blockNumber = static_cast&lt;unsigned&gt;(info.number());if (blockNumber &gt; (m_lastImportedBlock + 1)){ LOG(m_loggerDetail) &lt;&lt; \"Received unknown new block\"; // Update the hash of highest known block of the peer. // syncPeer will then request the highest block header to properly restart syncing _peer-&gt;m_latestHash = h; syncPeer(_peer, true); return;} 这个包不同于之前的区块数据包，这个包里同时包含区块头和区块体，第一部分是对区块头里的信息进行处理。如果新收到的区块比我目前最新的节点更新，那么说明该节点有更新的数据，那么就调用syncPeer从该节点进行同步。第二部分就是导入区块体了： 12345switch (host().bq().import(_r[0].data())){case ImportResult::Success: // ...} 这里的流程和前一节差不多，将这个区块导入二级缓冲区中去验证。 几点补充到这里ETH区块链同步的主要流程都涉及到了，剩下的部分单独再分析。本节再对同步补充几点： 以太坊ropsten网络比主网mainnet要差很多，对于同步来说就是噩梦。如果需要测试交易什么的建议自己搭建私有链来测试. 同步过程漫长，需要有耐心，而且是越来越慢，后期单个区块包含的交易更多，计算量和存储量都巨大。 同步硬盘建议SSD，容量在1TB以上。 同步存储主要是三类数据库，Block数据库，Extra数据库和State数据库，其中State数据库最大，这个就是所谓的世界状态了。 同步有坑！！！，还记得以太坊C++源码解析（五）区块链同步(2)里的那张图吗？整个流程有两个阀门，阀门1是从BlockQueue到区块链，阀门2是从网络到一级缓冲区。这两个阀门正常工作流程是这样的：当二级缓冲区里有数据时，阀门1开启，否则关闭；另外由于数据进入二级缓冲区的速度通常比从二级缓冲区进入区块链的速度要快很多，因此二级缓冲区里有大量数据，当二级缓冲区满时，阀门2关闭，否则开启。但是这两个阀门在实际测试中是存在故障的，阀门1故障的表现是数据校验后未打开，数据不会进入区块链，导致二级缓冲区一直满，从而导致阀门2一直关闭，整个同步过程停止，这种我称为撑死；阀门2故障的表现是在已关闭的情况下，二级缓冲区未满时不能正常打开，二级缓冲区数据全部被取光后整个同步过程停止，这种我称为饿死。","link":"/2019/07/04/以太坊C-源码解析（五）区块链同步-6/"},{"title":"以太坊C++源码解析（八）交易队列（二）","text":"交易队列的输入交易队列的输入有两个，分别是接收到其他节点的广播交易和自身节点提交的交易。 分别来看这两种输入方式： 接收广播交易在前面区块链同步章节中提到过，接收到交易后会通过调用TransactionQueue::enqueue()来将新交易放入交易队列中，这个函数代码非常简单：123456789101112131415161718192021void TransactionQueue::enqueue(RLP const&amp; _data, h512 const&amp; _nodeId){ bool queued = false; { Guard l(x_queue); unsigned itemCount = _data.itemCount(); for (unsigned i = 0; i &lt; itemCount; ++i) { if (m_unverified.size() &gt;= c_maxVerificationQueueSize) { LOG(m_logger) &lt;&lt; \"Transaction verification queue is full. Dropping \" &lt;&lt; itemCount - i &lt;&lt; \" transactions\"; break; } m_unverified.emplace_back(UnverifiedTransaction(_data[i].data(), _nodeId)); queued = true; } } if (queued) m_queueReady.notify_all();} 只是将交易放入m_unverified中，然后通知校验线程来校验。再来看校验线程： 12345678910111213141516171819202122232425262728void TransactionQueue::verifierBody(){ while (!m_aborting) { UnverifiedTransaction work; { unique_lock&lt;Mutex&gt; l(x_queue); m_queueReady.wait(l, [&amp;](){ return !m_unverified.empty() || m_aborting; }); if (m_aborting) return; work = move(m_unverified.front()); m_unverified.pop_front(); } try { Transaction t(work.transaction, CheckTransaction::Cheap); //Signature will be checked later ImportResult ir = import(t); m_onImport(ir, t.sha3(), work.nodeId); } catch (...) { // should not happen as exceptions are handled in import. cwarn &lt;&lt; \"Bad transaction:\" &lt;&lt; boost::current_exception_diagnostic_information(); } }} 这里是一个简单的生产消费者队列，先将UnverifiedTransaction取出，然后调用import()函数进行校验。由于使用了线程，校验过程是异步的。 自身提交交易节点自身提交的交易与上面的交易不同，是同步的，也就是直接会调用import()函数来进行校验。123456789101112ImportResult TransactionQueue::import(bytesConstRef _transactionRLP, IfDropped _ik){ try { Transaction t = Transaction(_transactionRLP, CheckTransaction::Everything); return import(t, _ik); } catch (Exception const&amp;) { return ImportResult::Malformed; }} 交易的校验我们来看这个校验的过程，也就是TransactionQueue::import()函数。 12345678910111213141516171819202122ImportResult TransactionQueue::import(Transaction const&amp; _transaction, IfDropped _ik){ if (_transaction.hasZeroSignature()) return ImportResult::ZeroSignature; // Check if we already know this transaction. h256 h = _transaction.sha3(WithSignature); ImportResult ret; { UpgradableGuard l(m_lock); auto ir = check_WITH_LOCK(h, _ik); if (ir != ImportResult::Success) return ir; { _transaction.safeSender(); // Perform EC recovery outside of the write lock UpgradeGuard ul(l); ret = manageImport_WITH_LOCK(h, _transaction); } } return ret;} 可以看到先是调用TransactionQueue::check_WITH_LOCK()函数来做一个简单检查。检查的过程是看这个交易是否是已经校验过的，是否是之前被删除的。接着调用_transaction.safeSender()，这个函数是通过签名反推sender，在交易那一节已经说过。最后调用manageImport_WITH_LOCK()函数来处理交易。manageImport_WITH_LOCK()函数过程稍稍复杂，我们可以一步一步来分析。第一步： 12345678910111213141516auto cs = m_currentByAddressAndNonce.find(_transaction.from());if (cs != m_currentByAddressAndNonce.end()){ auto t = cs-&gt;second.find(_transaction.nonce()); if (t != cs-&gt;second.end()) { if (_transaction.gasPrice() &lt; (*t-&gt;second).transaction.gasPrice()) return ImportResult::OverbidGasPrice; else { h256 dropped = (*t-&gt;second).transaction.sha3(); remove_WITH_LOCK(dropped); m_onReplaced(dropped); } }} 这一步是检查m_currentByAddressAndNonce中是否有重复项，判断标准是sender和nonce，如果存在重复的则检查gasPrice，如果新的交易gasPrice更低，则校验失败，否则将现有的交易删除，替换为gasPrice更高的交易。第二步是检查m_future，检查过程与第一步类似。第三步： 1234567891011// If valid, append to transactions.insertCurrent_WITH_LOCK(make_pair(_h, _transaction));LOG(m_loggerDetail) &lt;&lt; \"Queued vaguely legit-looking transaction \" &lt;&lt; _h;while (m_current.size() &gt; m_limit){ LOG(m_loggerDetail) &lt;&lt; \"Dropping out of bounds transaction \" &lt;&lt; _h; remove_WITH_LOCK(m_current.rbegin()-&gt;transaction.sha3());}m_onReady(); 这里调用insertCurrent_WITH_LOCK()插入队列，然后将超出容量m_limit的部分删除，并调用m_onReady()表示目前队列有数据了，可以来取了。我们再来看insertCurrent_WITH_LOCK()函数是怎么将交易插入队列的。 12345678910111213141516171819void TransactionQueue::insertCurrent_WITH_LOCK(std::pair&lt;h256, Transaction&gt; const&amp; _p){ if (m_currentByHash.count(_p.first)) { cwarn &lt;&lt; \"Transaction hash\" &lt;&lt; _p.first &lt;&lt; \"already in current?!\"; return; } Transaction const&amp; t = _p.second; // Insert into current auto inserted = m_currentByAddressAndNonce[t.from()].insert(std::make_pair(t.nonce(), PriorityQueue::iterator())); PriorityQueue::iterator handle = m_current.emplace(VerifiedTransaction(t)); inserted.first-&gt;second = handle; m_currentByHash[_p.first] = handle; // Move following transactions from future to current makeCurrent_WITH_LOCK(t); m_known.insert(_p.first);} 先还是检查是否有重复项，然后把交易插入m_current里，并记下插入的位置(迭代器)，再分别加入m_currentByAddressAndNonce和m_currentByHash中。注意到末尾还有个makeCurrent_WITH_LOCK()的调用，这个是看情况将m_future里的交易移到m_current中。 交易队列的输出交易队列输出只有一个，那就是区块block。在Block::sync()中会调用TransactionQueue::topTransactions()来取队列的前N项数据，再加入block中。","link":"/2019/07/04/以太坊C-源码解析（八）交易队列（二）/"},{"title":"以太坊C-源码解析（十）以太坊交易中的nonce","text":"以太坊交易中存在一个特殊的值nonce，此nonce并非计算block难度的nonce，此nonce仅仅表示发送账号发送交易的次数，从0开始，每发送一次交易+1，那么第一次发送nonce为0，第二次为1，以此类推。nonce的存在可以用来防止重放攻击，也就是同一个交易只能被发送一次，下次发送同一个交易时，因为nonce值和最新的nonce不同，会被区块链拒绝。我们来从代码层面看看这个nonce的生成和检测。 我们可以从一张图来看这个nonce的来龙去脉。可以看到这张图上存在一个关键性的三角关系。 三角形上面顶点是区块链blockchain。 左边顶点是postseal()中的nonce，postseal()是从区块链获取到的最新的区块，那么左边顶点表示当前区块链中最新区块该发送账号的nonce。 右边顶点是交易队列中的nonce当我们提交一个交易时，交易的nonce取值是左右两个顶点的nonce值中取最大值。然后再与blockchain中最新块的nonce进行比较，如果不同，则区块链拒绝此交易。那么问题来了，postseal()中不就是最新块的nonce吗？为什么还需要再次比较？这是因为postseal()并不是一直与区块链同步的，只有满足某些条件才会同步。另外当交易成功提交后，该交易在正式被区块链确认前，是被存放在交易队列中的，此时右顶点的nonce值为该交易的nonce+1。 我们来一步一步拆开来看：第一步，假设该发送者从来没有发送过交易，那么他的nonce值应该为0，上面的图会变成：此时blockchain和postseal()中均没有该账号的信息，nonce值为初始值0。 交易队列中没有该发送账号的交易，因此nonce值也是0，那么该发送者第一次提交交易时，nonce值会被设置为max(0, 0)，也就是0。然后再比较0与0是相等的，那么此交易被正确发送。 第二步，交易被发送到交易队列，这张图变成：此时上顶点和左顶点的nonce值不变，右顶点因为交易队列中已有一个该发送者发送的交易，那么nonce+1，变成1。此时如果该发送者想再发一个交易，那么新交易的nonce会被设置为max(0, 1)，也就是1。然后再与上顶点nonce比较，得出不相等的结论，此交易被拒绝，提交失败！ 第三步，第一个交易被区块链确认，这张图变成：交易被确认后，上顶点blockchain的nonce变成1，左顶点因为同步，nonce也变成1，而右顶点交易队列会删除掉已确认的交易，所以没有该发送者的交易了，nonce就为0。此时如果该发送者再发一个交易，新交易的nonce会被设置为max(1, 0)，也就是1。然后再与上顶点nonce比较，结果相等，该交易被成功发出！ 交易被发出后被发到交易队列，流程就同第二步了。 下面我们来看看具体涉及到的代码实现： 1234567891011121314151617TransactionSkeleton Client::populateTransactionWithDefaults(TransactionSkeleton const&amp; _t) const{ TransactionSkeleton ret(_t); // Default gas value meets the intrinsic gas requirements of both // send value and create contract transactions and is the same default // value used by geth and testrpc. const u256 defaultTransactionGas = 90000; if (ret.nonce == Invalid256) ret.nonce = max&lt;u256&gt;(postSeal().transactionsFrom(ret.from), m_tq.maxNonce(ret.from)); if (ret.gasPrice == Invalid256) ret.gasPrice = gasBidPrice(); if (ret.gas == Invalid256) ret.gas = defaultTransactionGas; return ret;} 这段代码是提交交易时设置交易的一些参数，其中 1ret.nonce = max&lt;u256&gt;(postSeal().transactionsFrom(ret.from), m_tq.maxNonce(ret.from)); 就是设置交易的nonce，是左顶点和右顶点的nonce值的最大值。 再来看交易队列中的nonce： 1234567891011121314151617u256 TransactionQueue::maxNonce(Address const&amp; _a) const{ ReadGuard l(m_lock); return maxNonce_WITH_LOCK(_a);}u256 TransactionQueue::maxNonce_WITH_LOCK(Address const&amp; _a) const{ u256 ret = 0; auto cs = m_currentByAddressAndNonce.find(_a); if (cs != m_currentByAddressAndNonce.end() &amp;&amp; !cs-&gt;second.empty()) ret = cs-&gt;second.rbegin()-&gt;first + 1; auto fs = m_future.find(_a); if (fs != m_future.end() &amp;&amp; !fs-&gt;second.empty()) ret = std::max(ret, fs-&gt;second.rbegin()-&gt;first + 1); return ret;} 注意那个+1，这个表示当前队列中该发送者最大的nonce再+1。 而postseal()从区块链同步的代码在： 12345678910111213141516171819202122232425void Client::restartMining(){ bool preChanged = false; Block newPreMine(chainParams().accountStartNonce); DEV_READ_GUARDED(x_preSeal) newPreMine = m_preSeal; // TODO: use m_postSeal to avoid re-evaluating our own blocks. preChanged = newPreMine.sync(bc()); if (preChanged || m_postSeal.author() != m_preSeal.author()) { DEV_WRITE_GUARDED(x_preSeal) m_preSeal = newPreMine; DEV_WRITE_GUARDED(x_working) m_working = newPreMine; /// ... DEV_READ_GUARDED(x_working) DEV_WRITE_GUARDED(x_postSeal) m_postSeal = m_working; /// ... } /// ...} 省略了一些次要代码，从这里可以看出，先是从区块链同步最新信息到newPreMine，然后拷贝到m_postSeal，也就是postseal()。 那么Client::restartMining()是从哪里调用的呢？有两个地方，但是一般都是从Client::resyncStateFromChain()这里调用的： 123456void Client::resyncStateFromChain(){ /// ... restartMining();} Client::resyncStateFromChain()函数又是从哪里调用呢？也有两个地方，一处是Client::onChainChanged()表示区块链同步新块的时候，另一处是Client::syncTransactionQueue()表示同步交易队列中交易的时候。由此可见，以太坊通过这些机制保证nonce与发送账号的发送次数严格对应，如果发送交易不遵守这条规则，则发送可能会失败，错误码为InvalidNonce","link":"/2019/07/15/以太坊C-源码解析（十）以太坊交易中的nonce/"},{"title":"以太坊C++源码解析（五）区块链同步(5)","text":"onPeerBlockBodies()BlockChainSync::requestBlocks()请求区块体后，如果对方有这些区块就会把数据返回回来，本节我们来看看接收区块体数据的处理。 数据包辗转从Session到EthereumPeer，再到EthereumPeerObserver，最后到BlockChainSync::onPeerBlockBodies中。 1234567891011121314151617181920RecursiveGuard l(x_sync);DEV_INVARIANT_CHECK;size_t itemCount = _r.itemCount();LOG(m_logger) &lt;&lt; \"BlocksBodies (\" &lt;&lt; dec &lt;&lt; itemCount &lt;&lt; \" entries) \" &lt;&lt; (itemCount ? \"\" : \": NoMoreBodies\");clearPeerDownload(_peer);if (m_state != SyncState::Blocks &amp;&amp; m_state != SyncState::Waiting) { LOG(m_logger) &lt;&lt; \"Ignoring unexpected blocks\"; return;}if (m_state == SyncState::Waiting){ LOG(m_loggerDetail) &lt;&lt; \"Ignored blocks while waiting\"; return;}if (itemCount == 0){ LOG(m_loggerDetail) &lt;&lt; \"Peer does not have the blocks requested\"; _peer-&gt;addRating(-1);} 这个函数比onPeerBlockHeaders()简单多了，开头仍然主要是对SyncState做检查。接着是遍历校验接收到的区块体： 1234567891011121314151617181920212223for (unsigned i = 0; i &lt; itemCount; i++){ RLP body(_r[i]); auto txList = body[0]; h256 transactionRoot = trieRootOver(txList.itemCount(), [&amp;](unsigned i){ return rlp(i); }, [&amp;](unsigned i){ return txList[i].data().toBytes(); }); h256 uncles = sha3(body[1].data()); HeaderId id { transactionRoot, uncles }; auto iter = m_headerIdToNumber.find(id); if (iter == m_headerIdToNumber.end() || !haveItem(m_headers, iter-&gt;second)) { LOG(m_loggerDetail) &lt;&lt; \"Ignored unknown block body\"; continue; } unsigned blockNumber = iter-&gt;second; if (haveItem(m_bodies, blockNumber)) { LOG(m_logger) &lt;&lt; \"Skipping already downloaded block body \" &lt;&lt; blockNumber; continue; } m_headerIdToNumber.erase(id); mergeInto(m_bodies, blockNumber, body.data().toBytes());} 校验过程也比较简单，主要是从区块体数据中重新计算transactionRoot和uncles值，和m_headers中对应块头里记录的值做比较，如果一样则mergeInto到m_bodies里。最后仍然是： 12collectBlocks();continueSync(); 但是这次我们需要深入collectBlocks()这个函数里去看看了，因为这次有了区块头和区块体，只要条件允许就可以进行合并操作了。 collectBlocks()BlockChainSync::collectBlocks()函数开头就提出合并所需要的两组条件。第一组条件是： 12if (!m_haveCommonHeader || m_headers.empty() || m_bodies.empty()) return; 第一组包含三个条件，缺一不可。第二组条件是： 1234auto&amp; headers = *m_headers.begin();auto&amp; bodies = *m_bodies.begin();if (headers.first != bodies.first || headers.first != m_lastImportedBlock + 1) return; 这里的headers是m_headers中第一个连续区域，bodies是m_bodies中第一个连续区域。那么这里的两个条件是headers中最低区块号必须和bodies中最低区块号相同，并且这个区块号就是所需要同步的下一个区块。满足这两个条件就可以进入正式的合并流程了，在BlockChainSync里的部分其实并不多： 1234567891011121314for (; i &lt; headers.second.size() &amp;&amp; i &lt; bodies.second.size(); i++){ RLPStream blockStream(3); blockStream.appendRaw(headers.second[i].data); RLP body(bodies.second[i]); blockStream.appendRaw(body[0].data()); blockStream.appendRaw(body[1].data()); bytes block; blockStream.swapOut(block); switch (host().bq().import(&amp;block)) { // ... }} 假如headers里的区块是[区块3，区块4，区块5，区块6]，bodies里的区块是[区块3，区块4]，那么这里的遍历范围是[区块3，区块4]。将区块头和区块体合并起来以后放到RLPStream中，并调用BlockQueue::import()函数导入二级缓冲区中，BlockQueue::import()函数的实现在以后BlockQueue类里再细说，这里主要看BlockChainSync类里的流程。调用完BlockQueue::import()后根据返回值做不同处理，这段就不分析了，可以直接去看源码。 123456789101112auto newHeaders = std::move(headers.second);newHeaders.erase(newHeaders.begin(), newHeaders.begin() + i);unsigned newHeaderHead = headers.first + i;auto newBodies = std::move(bodies.second);newBodies.erase(newBodies.begin(), newBodies.begin() + i);unsigned newBodiesHead = bodies.first + i;m_headers.erase(m_headers.begin());m_bodies.erase(m_bodies.begin());if (!newHeaders.empty()) m_headers[newHeaderHead] = newHeaders;if (!newBodies.empty()) m_bodies[newBodiesHead] = newBodies; 导入二级缓冲区后，将导入成功的区块从headers和bodies中删除，并重设m_headers和m_bodies中的最低连续区域。","link":"/2019/07/04/以太坊C-源码解析（五）区块链同步-5/"},{"title":"以太坊C++源码解析（八）交易队列（一）","text":"以太坊有两大队列，分别是交易队列TransactionQueue和区块队列BlockQueue，在这里先介绍交易队列。交易队列是用来缓存那些pending交易的，也就是尚未经过确认，未被区块链收录的交易。 我们先来看看它有哪些重要成员。 已校验交易123PriorityQueue m_current;std::unordered_map&lt;h256, PriorityQueue::iterator&gt; m_currentByHash; ///&lt; Transaction hash to set refstd::unordered_map&lt;Address, std::map&lt;u256, PriorityQueue::iterator&gt;&gt; m_currentByAddressAndNonce; ///&lt; Transactions grouped by account and nonce 这三个成员都是表示当前队列中已经过校验的交易，其中最重要的是m_current，其他两个记录的都是m_current中的迭代器，用于快速读取m_current中的交易数据。而PriorityQueue是一个std::multiset的别名: 1using PriorityQueue = std::multiset&lt;VerifiedTransaction, PriorityCompare&gt;; 表明在这个multiset里存储的是VerifiedTransaction，并按PriorityCompare排序，我们来看排序方法： 1234567891011struct PriorityCompare{ TransactionQueue&amp; queue; /// Compare transaction by nonce height and gas price. bool operator()(VerifiedTransaction const&amp; _first, VerifiedTransaction const&amp; _second) const { u256 const&amp; height1 = _first.transaction.nonce() - queue.m_currentByAddressAndNonce[_first.transaction.sender()].begin()-&gt;first; u256 const&amp; height2 = _second.transaction.nonce() - queue.m_currentByAddressAndNonce[_second.transaction.sender()].begin()-&gt;first; return height1 &lt; height2 || (height1 == height2 &amp;&amp; _first.transaction.gasPrice() &gt; _second.transaction.gasPrice()); }}; 这个排序结构保存有交易队列的引用，具体的排序方法为：先计算当前交易的nonce与同一个sender的第一个交易的nonce的差值，也就是height1和height2，如果height1 &lt; height2，则交易1排在交易2的前面。如果height1 == height2，则比较两个交易的gasPrice，价高的交易排在前面，我们所说的gasPrice越高的交易越快被确认就是因为这个处理。除了m_current，还有m_future： 1std::unordered_map&lt;Address, std::map&lt;u256, VerifiedTransaction&gt;&gt; m_future; /// Future transactions 这里存储的是future的交易，比如对于某个sender当前最新的nonce是4，那么该sender下一个交易的nonce应该是5，如果此时交易队列收到一个交易是sender发出的，但是nonce值不是5，比如是7，那么这个交易被认为是未来的，不是当下的，会被保存到m_future里，而不是m_current，而当m_current里有了来自该sender的nonce为5和6的交易后，之前那个nonce为7的交易会从m_future移到m_current中。 未校验交易交易队列还负责校验未校验交易： 12std::vector&lt;std::thread&gt; m_verifiers;std::deque&lt;UnverifiedTransaction&gt; m_unverified; ///&lt; Pending verification queue 交易队列内置若干个交易线程来完成交易的初步校验，注意这里只是初步校验，并不是很严格。未校验的交易暂时保存在m_unverified中，校验过后移到m_current里。那么未校验的交易是从哪里来的呢？在本节点提交的交易除了自身校验外，还需要广播到其他节点，其他节点收到后，会将这些交易收录到m_unverified中，作为未确认交易处理。 消息回调交易队列除了保存交易，还对外提供了回调接口，方便与其他模块的交互。 123Signal&lt;&gt; m_onReady; ///&lt; Called when a subsequent call to import transactions will return a non-empty container. Be nice and exit fast.Signal&lt;ImportResult, h256 const&amp;, h512 const&amp;&gt; m_onImport; ///&lt; Called for each import attempt. Arguments are result, transaction id an node id. Be nice and exit fast.Signal&lt;h256 const&amp;&gt; m_onReplaced; ///&lt; Called whan transction is dropped during a call to import() to make room for another transaction. 这三个成员变量分别表示三组回调函数，其中m_onReady表示交易队列已经准备好可以将交易打包到block里了。m_onImport表示当前正在向交易队列中导入未校验交易。m_onReplaced表示从交易队列中删除某个交易。Signal定义为一组不定长参数的function，其中Signal&lt;&gt;可以简单看作是： 1std::map&lt;unsigned, std::weak_ptr&lt;std::function&lt;&gt;&gt; map中的第一项表示序号，第二项表示回调函数。有兴趣的同学可以去libethcore\\Common.h中去查看Signal这个模板类的源码。","link":"/2019/07/04/以太坊C-源码解析（八）交易队列（一）/"},{"title":"以太坊C++源码解析（五）区块链同步(3)","text":"经过前面的铺垫，现在我们可以来看看BlockChainSync::onPeerBlockHeaders()这个函数的实现了，这个函数是EthereumPeer接收到BlockHeadersPacket包时被调用的，用来处理接收到的区块头。这个函数有点长，还是一段一段来看吧。 12345678910if (m_daoChallengedPeers.find(_peer) != m_daoChallengedPeers.end()){ if (verifyDaoChallengeResponse(_r)) syncPeer(_peer, false); else _peer-&gt;disable(\"Peer from another fork.\"); m_daoChallengedPeers.erase(_peer); return;} 这段是处理DAO分叉，在以太坊C++源码解析（六）以太坊The DAO分叉里已经讲过。 12345678910111213141516clearPeerDownload(_peer);if (m_state != SyncState::Blocks &amp;&amp; m_state != SyncState::Waiting){ LOG(m_logger) &lt;&lt; \"Ignoring unexpected blocks\"; return;}if (m_state == SyncState::Waiting){ LOG(m_loggerDetail) &lt;&lt; \"Ignored blocks while waiting\"; return;}if (itemCount == 0){ LOG(m_loggerDetail) &lt;&lt; \"Peer does not have the blocks requested\"; _peer-&gt;addRating(-1);} 这部分中clearPeerDownload()函数用来清除该peer的m_downloadingHeaders，m_downloadingBodies等，以便重新获取，然后是同步状态的检测。接着是遍历接收的数据头： 12345678910111213141516171819202122for (unsigned i = 0; i &lt; itemCount; i++){ BlockHeader info(_r[i].data(), HeaderData); unsigned blockNumber = static_cast&lt;unsigned&gt;(info.number()); if (blockNumber &lt; m_chainStartBlock) { LOG(m_logger) &lt;&lt; \"Skipping too old header \" &lt;&lt; blockNumber; continue; } if (haveItem(m_headers, blockNumber)) { LOG(m_logger) &lt;&lt; \"Skipping header \" &lt;&lt; blockNumber &lt;&lt; \" (already downloaded)\"; continue; } if (blockNumber &lt;= m_lastImportedBlock &amp;&amp; m_haveCommonHeader) { LOG(m_logger) &lt;&lt; \"Skipping header \" &lt;&lt; blockNumber &lt;&lt; \" (already imported)\"; continue; } if (blockNumber &gt; m_highestBlock) m_highestBlock = blockNumber; // ... info是BlockHeader类对象，blockNumber是块号，检查是否该块头已经在下载缓冲区m_headers中等等。下面这段就比较关键了，可以完整贴出来： 123456789101112131415161718auto status = host().bq().blockStatus(info.hash());if (status == QueueStatus::Importing || status == QueueStatus::Ready || host().chain().isKnown(info.hash())){ m_haveCommonHeader = true; m_lastImportedBlock = (unsigned)info.number(); m_lastImportedBlockHash = info.hash(); if (!m_headers.empty() &amp;&amp; m_headers.begin()-&gt;first == m_lastImportedBlock + 1 &amp;&amp; m_headers.begin()-&gt;second[0].parent != m_lastImportedBlockHash) { // Start of the header chain in m_headers doesn't match our known chain, // probably we've downloaded other fork clog(VerbosityWarning, \"sync\") &lt;&lt; \"Unknown parent of the downloaded headers, restarting sync\"; restartSync(); return; }} 在上一篇提到过区块链同步的回退操作，那么回退到什么时候刹住车呢？就是在这里判断的，假如这个块头在BlockQueue中导入过或者正在导入或者直接就在本地区块链中，那么就认为该区块头是可信的，就不需要再继续回退了，并将m_haveCommonHeader设为true。既然这个区块头是可信的，那么就可以用它来检测m_headers里还在排队的区块里有没有不是一条心的。假如m_headers中块号最小的那个块恰好是这个区块的下一个块(块号+1)，并且那个块的父块又不是这个区块，那就说明m_headers里下载的区块有问题了，这个时候的处理是清空缓冲区，重新开始同步restartSync()。 如果这个区块头是新下载的区块头，并且当前不是在回退操作中，那么也要做检查，这里的检查要稍微复杂一些，既需要检查下载区块的下一个区块，又要检查下载区块的上一个区块： 123456789101112131415161718192021222324252627282930313233if (m_haveCommonHeader){ Header const* prevBlock = findItem(m_headers, blockNumber - 1); if ((prevBlock &amp;&amp; prevBlock-&gt;hash != info.parentHash()) || (blockNumber == m_lastImportedBlock + 1 &amp;&amp; info.parentHash() != m_lastImportedBlockHash)) { // mismatching parent id, delete the previous block and don't add this one clog(VerbosityWarning, \"sync\") &lt;&lt; \"Unknown block header \" &lt;&lt; blockNumber &lt;&lt; \" \" &lt;&lt; info.hash() &lt;&lt; \" (Restart syncing)\"; _peer-&gt;addRating(-1); restartSync(); return ; } Header const* nextBlock = findItem(m_headers, blockNumber + 1); if (nextBlock &amp;&amp; nextBlock-&gt;parent != info.hash()) { LOG(m_loggerDetail) &lt;&lt; \"Unknown block header \" &lt;&lt; blockNumber + 1 &lt;&lt; \" \" &lt;&lt; nextBlock-&gt;hash; // clear following headers unsigned n = blockNumber + 1; auto headers = m_headers.at(n); for (auto const&amp; h : headers) { BlockHeader deletingInfo(h.data, HeaderData); m_headerIdToNumber.erase(headerId); m_downloadingBodies.erase(n); m_downloadingHeaders.erase(n); ++n; } removeAllStartingWith(m_headers, blockNumber + 1); removeAllStartingWith(m_bodies, blockNumber + 1); }} 这里还是将m_headers中已下载的区块拿来做比较，如果m_headers中有下载区块的下一个区块，并且下一个区块的父区块不是下载区块或者下载区块是当前需要下载的下一个区块，但是下载区块的父区块不是上一个已下载的区块，那么也需要清空缓冲区，重新开始同步。这段文字比较拗口，还是直接看代码更容易理解。检查下载区块的下一个区块也是类似的方法，但是有点区别的是这里如果检查未通过并不是重新开始同步，而是将m_headers，m_bodies等缓冲区里下载区块的后续区块清除掉。检查通过之后，就可以将下载区块头加入m_headers中了： 12345678910111213mergeInto(m_headers, blockNumber, std::move(hdr));if (headerId.transactionsRoot == EmptyTrie &amp;&amp; headerId.uncles == EmptyListSHA3){ //empty body, just mark as downloaded RLPStream r(2); r.appendRaw(RLPEmptyList); r.appendRaw(RLPEmptyList); bytes body; r.swapOut(body); mergeInto(m_bodies, blockNumber, std::move(body));}else m_headerIdToNumber[headerId] = blockNumber; 这里有一种特殊的区块，就是区块本身并不包含交易，也就是区块体是空的，那么我们就可以直接将一个空的区块体添加到m_bodies中，而不需要再去下载该区块体了。所有工作都完成以后是两个函数的调用： 12collectBlocks();continueSync(); 其中collectBlocks()是判断是否有合适的区块头和区块体需要合并写入二级缓冲区BlockQueue，continueSync()是继续调用syncPeer()向其他peer请求区块头或者区块体。","link":"/2019/07/04/以太坊C-源码解析（五）区块链同步-3/"},{"title":"以太坊C++源码解析（六）以太坊The DAO分叉","text":"刚写了一篇区块链同步的文章，发现里面有一些DAO分叉的代码绕不过去，需要专门写一篇来简单介绍一下这次以太坊历史上著名的分叉事件。 区块链分叉分为硬分叉和软分叉，区别请自行谷歌，The DAO分叉是一次硬分叉。 The DAO是一个存在于以太坊区块链智能合约中的去中心化组织，这个组织于2016年4月30日起通过合约发起众筹，短短28天就筹集了相当于1.5亿美金的以太币。然而很不幸的是合约本身存在漏洞，更不幸的是被一个(多个?)聪明的黑客利用了，6月17日他(他们?)从中盗走了价值5000万美元的以太币。巨大的损失让The DAO和全球投资者难以承受，以V神为代表的7人组决定采取反制措施，当初采取软分叉还是硬分叉在社区是有争议的，但是经过各种厉害权衡，硬分叉的方案被确定了下来。 这次分叉本身也存在很大争议，相当于网游中的回档，直接宣布黑客所拥有的以太币是无效的，简单粗暴，但是违反了区块链上已打包交易任何人无法篡改的原则，人为地干预区块链也违背了去中心化的精神。因此分叉后以太坊就此分裂，由V神和大多数人支持的一支叫以太坊(ETH)，另一只叫以太经典(ETC)。ETC由于缺乏官方的支持，处于弱势，但是还是有一批坚守区块链精神的人在维持。 这次硬分叉的方案是这样的： 分叉的节点位于1920000高度的区块，该区块的extra data设为dao-hard-fork (Hex:0x64616f2d686172642d666f726b)，作为ETH和ETC区分的标志。 将DAO账户的所有余额全部转到一个退款合约账户上。 在1920000块上总计有58个DAO和子DAO合约账户的共12,001,961.845205763407115004 ETH被转到了退款合约账户上。这些转账没有在块交易中体现，而是直接被写入源码中！你可以在Etherscan上找到这个区块：区块1920000 下面我们来看看这个分叉在源码中的体现： 首先是记录了分叉点。libethashseal\\genesis\\mainNetwork.cpp里记录了mainnet的一些参数，其中就有&quot;daoHardforkBlock&quot;: &quot;0x1d4c00&quot;，0x1d4c00就是1920000！libethashseal\\genesis目录下的ropsten.cpp里记录了ropsten测试链的参数，可以看到ropsten的daoHardforkBlock值为0，表示没有分叉。 在Block::performIrregularModifications()函数中完成了转账操作。 123456789101112void Block::performIrregularModifications(){ u256 const&amp; daoHardfork = m_sealEngine-&gt;chainParams().daoHardforkBlock; if (daoHardfork != 0 &amp;&amp; info().number() == daoHardfork) { Address recipient(\"0xbf4ed7b27f1d666546e30d74d50d173d20bca754\"); Addresses allDAOs = childDaos(); for (Address const&amp; dao: allDAOs) m_state.transferBalance(dao, recipient, m_state.balance(dao)); m_state.commit(State::CommitBehaviour::KeepEmptyAccounts); }} 这段代码判断如果当前块高度为1920000时，遍历所有的DAO账号，将所有余额转到recipient中，recipient就是那个退款合约账户。分叉影响也波及到了区块链同步模块： 收到peer的StatusPacket包后，需要进行一个DAO challenge。BlockChainSync::onPeerStatus()中有如下代码： 123456// Before starting to exchange the data with the node, let's verify that it's on our chainif (!requestDaoForkBlockHeader(_peer)){ // DAO challenge not needed syncPeer(_peer, false);} BlockChainSync::requestDaoForkBlockHeader()函数实现为： 1234567891011bool BlockChainSync::requestDaoForkBlockHeader(std::shared_ptr&lt;EthereumPeer&gt; _peer){ // DAO challenge unsigned const daoHardfork = static_cast&lt;unsigned&gt;(host().chain().sealEngine()-&gt;chainParams().daoHardforkBlock); if (daoHardfork == 0) return false; m_daoChallengedPeers.insert(_peer); _peer-&gt;requestBlockHeaders(daoHardfork, 1, 0, false); return true;} 对于mainnet来说，daoHardfork为1920000，因此它首先需要向该peer请求这个分叉块头。 收到对方的BlockHeadersPacket包后还需要校验： 12345678910if (m_daoChallengedPeers.find(_peer) != m_daoChallengedPeers.end()){ if (verifyDaoChallengeResponse(_r)) syncPeer(_peer, false); else _peer-&gt;disable(\"Peer from another fork.\"); m_daoChallengedPeers.erase(_peer); return;} 校验的代码位于BlockChainSync::verifyDaoChallengeResponse()函数中： 123456789bool BlockChainSync::verifyDaoChallengeResponse(RLP const&amp; _r){ if (_r.itemCount() != 1) return false; BlockHeader info(_r[0].data(), HeaderData); return info.number() == host().chain().sealEngine()-&gt;chainParams().daoHardforkBlock &amp;&amp; info.extraData() == fromHex(\"0x64616f2d686172642d666f726b\");} 可以看到校验的方法很简单，就是看块头的extraData里记录的是不是dao-hard-fork (Hex:0x64616f2d686172642d666f726b)，如果是则说明是ETH，可以继续同步，否则是ETC，禁用该peer。节点通过DAO challenge后就可以按正常流程同步了。","link":"/2019/07/04/以太坊C-源码解析（六）以太坊The-DAO分叉/"},{"title":"以太坊C++源码解析（三）p2p(6)","text":"上一节中留了一个悬念，那就是在Session类中我们没有找到有意义的处理代码，这部分代码隐藏在哪里呢？ 答案其实在上上节的末尾中 那就是EthereumHost::newPeerCapability()实现中！我们来看下这个函数的实现： 123456789101112131415161718shared_ptr&lt;Capability&gt; EthereumHost::newPeerCapability(shared_ptr&lt;SessionFace&gt; const&amp; _s, unsigned _idOffset, p2p::CapDesc const&amp; _cap){ auto ret = HostCapability&lt;EthereumPeer&gt;::newPeerCapability(_s, _idOffset, _cap); auto cap = capabilityFromSession&lt;EthereumPeer&gt;(*_s, _cap.second); assert(cap); cap-&gt;init( protocolVersion(), m_networkId, m_chain.details().totalDifficulty, m_chain.currentHash(), m_chain.genesisHash(), m_hostData, m_peerObserver ); return ret;} 这个函数上来先调用了父类的实现，然后调用capabilityFromSession&lt;EthereumPeer&gt;()函数返回EthereumPeer对象的指针，最后调用了EthereumPeer::init()。看来有必要深入这个函数里看看。 1234567void EthereumPeer::init(unsigned _hostProtocolVersion, u256 _hostNetworkId, u256 _chainTotalDifficulty, h256 _chainCurrentHash, h256 _chainGenesisHash, shared_ptr&lt;EthereumHostDataFace&gt; _hostData, shared_ptr&lt;EthereumPeerObserverFace&gt; _observer){ m_hostData = _hostData; m_observer = _observer; m_hostProtocolVersion = _hostProtocolVersion; requestStatus(_hostNetworkId, _chainTotalDifficulty, _chainCurrentHash, _chainGenesisHash);} 可以看到这里有我们感兴趣的requestStatus()这个函数了！EthereumPeer::requestStatus()函数实现也比较简单，就是向对方发送一个StatusPacket包： 12345678910void EthereumPeer::requestStatus(u256 _hostNetworkId, u256 _chainTotalDifficulty, h256 _chainCurrentHash, h256 _chainGenesisHash){ assert(m_asking == Asking::Nothing); setAsking(Asking::State); m_requireTransactions = true; RLPStream s; prep(s, StatusPacket, 5) &lt;&lt; m_hostProtocolVersion &lt;&lt; _hostNetworkId &lt;&lt; _chainTotalDifficulty &lt;&lt; _chainCurrentHash &lt;&lt; _chainGenesisHash; sealAndSend(s);} 这个数据包真正开始了与peer有意义的通讯！ 可以看到发送这个包的同时告知了对方我自己的版本号，网络id，区块链难度，当前区块链最新块hash值，当前区块链创世区块的hash值，这些信息非常重要！对端peer接收到这个StatusPacket包以后怎么应答呢？前面讲过EthereumPeer类是Session类的消息处理器，那么我们到EthereumPeer::interpret()中去寻找： 1234567891011121314151617 case StatusPacket: {cout &lt;&lt; \"StatusPacket\" &lt;&lt; endl; m_protocolVersion = _r[0].toInt&lt;unsigned&gt;(); m_networkId = _r[1].toInt&lt;u256&gt;(); m_totalDifficulty = _r[2].toInt&lt;u256&gt;(); m_latestHash = _r[3].toHash&lt;h256&gt;(); m_genesisHash = _r[4].toHash&lt;h256&gt;(); if (m_peerCapabilityVersion == m_hostProtocolVersion) m_protocolVersion = m_hostProtocolVersion; LOG(m_logger) &lt;&lt; \"Status: \" &lt;&lt; m_protocolVersion &lt;&lt; \" / \" &lt;&lt; m_networkId &lt;&lt; \" / \" &lt;&lt; m_genesisHash.hex().c_str() &lt;&lt; \", TD: \" &lt;&lt; m_totalDifficulty &lt;&lt; \" = \" &lt;&lt; m_latestHash.hex().c_str(); setIdle(); observer-&gt;onPeerStatus(dynamic_pointer_cast&lt;EthereumPeer&gt;(dynamic_pointer_cast&lt;EthereumPeer&gt;(shared_from_this()))); break; } 可以看到这里将对方的协议版本号，网络id等信息取出来，然后交给observer去处理。observer也是从EthereumPeer::init()函数中由EthereumHost类传过来的，所以还是要去EthereumHost那找，在EthereumHost类的构造函数中有这么一句话： 1m_peerObserver = make_shared&lt;EthereumPeerObserver&gt;(m_sync, m_tq); EthereumPeerObserver这个类其实是一个过渡类，我们可以看看它的实现： 12345678910111213void onPeerStatus(std::shared_ptr&lt;EthereumPeer&gt; _peer) override{ try { m_sync-&gt;onPeerStatus(_peer); } catch (FailedInvariant const&amp;) { // \"fix\" for https://github.com/ethereum/webthree-umbrella/issues/300 cwarn &lt;&lt; \"Failed invariant during sync, restarting sync\"; m_sync-&gt;restartSync(); }} 这个类里有许多这样的函数，都是过渡用的，其实真正调用的是m_sync里对应的函数。而m_sync从上面代码中可以看到其实是EthereumHost类里的m_sync，这个是BlockChainSync类对象。 因此我们能够得出结论，所有数据包都是由BlockChainSync类对象来处理的！ 我们再来看看BlockChainSync::onPeerStatus()函数的实现： 123456789101112131415161718192021222324252627282930313233void BlockChainSync::onPeerStatus(std::shared_ptr&lt;EthereumPeer&gt; _peer){ // ... char const* disconnectReason = nullptr; if (_peer-&gt;m_genesisHash != host().chain().genesisHash()) disconnectReason = \"Invalid genesis hash.\"; else if (_peer-&gt;m_protocolVersion != host().protocolVersion()) disconnectReason = \"Invalid protocol version.\"; else if (_peer-&gt;m_networkId != host().networkId()) disconnectReason = \"Invalid network identifier.\"; else if (session-&gt;info().clientVersion.find(\"/v0.7.0/\") != string::npos) disconnectReason = \"Blacklisted client version.\"; else if (host().isBanned(session-&gt;id())) disconnectReason = \"Peer banned for previous bad behaviour.\"; else if (_peer-&gt;m_asking != Asking::State &amp;&amp; _peer-&gt;m_asking != Asking::Nothing) disconnectReason = \"Peer banned for unexpected status message.\"; if (disconnectReason) { LOG(m_logger) &lt;&lt; \"Peer not suitable for sync: \" &lt;&lt; disconnectReason; cout &lt;&lt; \"Peer not suitable for sync: \" &lt;&lt; disconnectReason &lt;&lt; endl; _peer-&gt;disconnect(); return; } // Before starting to exchange the data with the node, let's verify that it's on our chain if (!requestDaoForkBlockHeader(_peer)) { // DAO challenge not needed cout &lt;&lt; \"onPeerStatus syncPeer\" &lt;&lt; endl; syncPeer(_peer, false); }} 这个函数先是做了一些检测，判断peer的一些参数和自己参数不一致就关闭连接。最后调用了syncPeer()来对peer进行区块链同步！","link":"/2019/07/04/以太坊C-源码解析（三）p2p-6/"},{"title":"以太坊C++源码解析（三）p2p(3)","text":"我们再来深入了解一下Host类里节点和本节点是怎么交互的，在上一节可以看到节点到了Host类后，会调用Host::connect来连接对方，我们可以看下connect()函数实现代码： 1234567891011121314151617181920212223242526272829303132void Host::connect(std::shared_ptr&lt;Peer&gt; const&amp; _p){ // ... bi::tcp::endpoint ep(_p-&gt;endpoint); cnetdetails &lt;&lt; \"Attempting connection to node \" &lt;&lt; _p-&gt;id &lt;&lt; \"@\" &lt;&lt; ep &lt;&lt; \" from \" &lt;&lt; id(); auto socket = make_shared&lt;RLPXSocket&gt;(m_ioService); socket-&gt;ref().async_connect(ep, [=](boost::system::error_code const&amp; ec) { // ... if (ec) { cnetdetails &lt;&lt; \"Connection refused to node \" &lt;&lt; _p-&gt;id &lt;&lt; \"@\" &lt;&lt; ep &lt;&lt; \" (\" &lt;&lt; ec.message() &lt;&lt; \")\"; // Manually set error (session not present) _p-&gt;m_lastDisconnect = TCPError; } else { cnetdetails &lt;&lt; \"Connecting to \" &lt;&lt; _p-&gt;id &lt;&lt; \"@\" &lt;&lt; ep; auto handshake = make_shared&lt;RLPXHandshake&gt;(this, socket, _p-&gt;id); { Guard l(x_connecting); m_connecting.push_back(handshake); } handshake-&gt;start(); } m_pendingPeerConns.erase(nptr); });} 可以看到先是创建了一个socket，然后用async_connect()异步去连接这个节点，连接成功后生成了一个RLPXHandshake类，并调用了RLPXHandshake::start()来开启握手流程，这里并没有连接成功后就传输数据，因为对方可能并不是一个ethereum节点，或者是运行协议不匹配的节点，握手流程就用来过滤掉不合格的节点，只有通过了握手流程才能进行数据交互。注：在cpp-ethereum项目中底层数据传输用的是boost::asio库，作为准标准库中一员，boost::asio广泛应用在c++跨平台网络开发中，不熟悉的读者建议先去网络上阅读相关文档，后续文档假定读者已经了解了boost::asio库。 #RLPXHandshake类RLPXHandshake::start()函数实际调用了RLPXHandshake::transition()函数，这个函数是RLPXHandshake类的核心，从中可以看到握手的流程。 12345678910111213141516171819202122232425262728293031323334353637383940void RLPXHandshake::transition(boost::system::error_code _ech){ // ... if (m_nextState == New) { m_nextState = AckAuth; if (m_originated) writeAuth(); else readAuth(); } else if (m_nextState == AckAuth) { m_nextState = WriteHello; if (m_originated) readAck(); else writeAck(); } else if (m_nextState == AckAuthEIP8) { m_nextState = WriteHello; if (m_originated) readAck(); else writeAckEIP8(); } else if (m_nextState == WriteHello) { m_nextState = ReadHello; // ... } else if (m_nextState == ReadHello) { // Authenticate and decrypt initial hello frame with initial RLPXFrameCoder // and request m_host to start session. m_nextState = StartSession; // ... }} 精简后的流程还是比较清楚的，初始时候m_nextState值为New，那么正常的握手状态是New -&gt; AckAuth -&gt; WriteHello -&gt; ReadHello -&gt; StartSession。如果这些环节中某一步出错了，那么该节点不会走到最后，否则最后的状态会变成StartSession，那么到了StartSession状态后会发生什么事呢？我们再看看看这部分代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748else if (m_nextState == ReadHello){ // Authenticate and decrypt initial hello frame with initial RLPXFrameCoder // and request m_host to start session. m_nextState = StartSession; // read frame header unsigned const handshakeSize = 32; m_handshakeInBuffer.resize(handshakeSize); ba::async_read(m_socket-&gt;ref(), boost::asio::buffer(m_handshakeInBuffer, handshakeSize), [this, self](boost::system::error_code ec, std::size_t) { if (ec) transition(ec); else { // ... /// rlp of header has protocol-type, sequence-id[, total-packet-size] bytes headerRLP(header.size() - 3 - h128::size); // this is always 32 - 3 - 16 = 13. wtf? bytesConstRef(&amp;header).cropped(3).copyTo(&amp;headerRLP); /// read padded frame and mac m_handshakeInBuffer.resize(frameSize + ((16 - (frameSize % 16)) % 16) + h128::size); ba::async_read(m_socket-&gt;ref(), boost::asio::buffer(m_handshakeInBuffer, m_handshakeInBuffer.size()), [this, self, headerRLP](boost::system::error_code ec, std::size_t) { // ... if (ec) transition(ec); else { // ... try { RLP rlp(frame.cropped(1), RLP::ThrowOnFail | RLP::FailIfTooSmall); m_host-&gt;startPeerSession(m_remote, rlp, move(m_io), m_socket); } catch (std::exception const&amp; _e) { cnetlog &lt;&lt; \"Handshake causing an exception: \" &lt;&lt; _e.what(); m_nextState = Error; transition(); } } }); } });} 当状态从ReadHello向StartSession转变时，连续收了两个包，然后调用了Host::startPeerSession()，节点在RLPXHandshake类转了一圈以后，如果合格的话又回到了Host类中，从此开始新的征程。 #Host类我们之前看到Host类通过requirePeer()函数推动了P2P发现模块的运转，但同时它又是整个P2P传输模块中的发动机，因此要研究ethereum网络部分需要从这里开始。我们在libp2p\\Host.h文件中找到Host类定义，其中有两个成员变量，熟悉boost::asio库的读者一定不陌生： 12ba::io_service m_ioService;bi::tcp::acceptor m_tcp4Acceptor; 其中m_ioService就是Host类的核心了，它负责处理异步任务，当异步任务完成后调用完成句柄。m_tcp4Acceptor是负责接收连接的对象，它内部封装了一个socket对象。我们都知道服务端的socket需要经过创建，绑定IP端口，侦听，Accept这几个阶段，对于m_tcp4Acceptor而言也是这样： 创建 直接在Host类初始化列表中进行创建 绑定IP端口和侦听 这部分是在Network::tcp4Listen()函数中完成的： 123456789101112131415161718192021222324252627for (unsigned i = 0; i &lt; 2; ++i){ bi::tcp::endpoint endpoint(listenIP, requirePort ? _netPrefs.listenPort : (i ? 0 : c_defaultListenPort)); try { /// ... _acceptor.open(endpoint.protocol()); _acceptor.set_option(ba::socket_base::reuse_address(reuse)); _acceptor.bind(endpoint); _acceptor.listen(); return _acceptor.local_endpoint().port(); } catch (...) { // bail if this is first attempt &amp;&amp; port was specificed, or second attempt failed (random port) if (i || requirePort) { // both attempts failed cwarn &lt;&lt; \"Couldn't start accepting connections on host. Failed to accept socket on \" &lt;&lt; listenIP &lt;&lt; \":\" &lt;&lt; _netPrefs.listenPort &lt;&lt; \".\\n\" &lt;&lt; boost::current_exception_diagnostic_information(); _acceptor.close(); return -1; } _acceptor.close(); continue; } } 注意到这里有一个循环，是用来防止端口被占用的。如果第一次端口被占用，则第二次使用0端口，也就是随机端口。在这个函数里，_acceptor依次完成了设置协议，设置端口重用，绑定端口和侦听。 Accept 又回到了Host类，在Host::runAcceptor()函数中，我们能找到以下代码： 12345678910111213141516171819202122232425auto socket = make_shared&lt;RLPXSocket&gt;(m_ioService); m_tcp4Acceptor.async_accept(socket-&gt;ref(), [=](boost::system::error_code ec){ // ... try { // incoming connection; we don't yet know nodeid auto handshake = make_shared&lt;RLPXHandshake&gt;(this, socket); m_connecting.push_back(handshake); handshake-&gt;start(); success = true; } catch (Exception const&amp; _e) { cwarn &lt;&lt; \"ERROR: \" &lt;&lt; diagnostic_information(_e); } catch (std::exception const&amp; _e) { cwarn &lt;&lt; \"ERROR: \" &lt;&lt; _e.what(); } if (!success) socket-&gt;ref().close(); runAcceptor();}); m_tcp4Acceptor通过async_accept()异步接收连接，当一个连接到来的时候发生了什么？我们又看到了熟悉的代码，是的！创建了一个RLPXHandshake类，又开始了握手流程。ethereum对于接收到的连接也是谨慎的，同样需要先进行校验，这里的握手流程与前面connect时的流程稍有不同，区别就在RLPXHandshake::m_originated上，connect时的m_originated值为true，也就是先向对方发送自己的Auth包，而被动接收时m_originated为false，会等待对方发过来Auth包。最后别忘了启动Host::m_ioService，这部分被放在doWork()函数里，还记得doWork()函数吗？因为Host类是从Worker类继承而来，doWork()会在一个循环中被调用。 123456789101112void Host::doWork(){ try { if (m_run) m_ioService.run(); } catch (std::exception const&amp; _e) { // ... }} 但是doWork()不是会被循环调用的吗？难道m_ioService.run()也会重复调用吗？答案是不会，因为m_ioService.run()会阻塞在这里，所以只会执行一次。至此m_tcp4Acceptor能够愉快地接收到TCP连接，并把连接交给RLPXHandshake类去处理了。","link":"/2019/07/02/以太坊C-源码解析（三）p2p-3/"},{"title":"以太坊C++源码解析（五）区块链同步(1)","text":"在p2p(6)那一节末尾我们涉及到了BlockChainSync::syncPeer()函数，实际上到这里已经进入了另外一个重要模块：区块链同步模块，这个模块算是P2P模块交互模块。 我们知道区块链是一个分布式账本，在所有的全节点上都有区块链的一个完整副本，这些全节点之间是相互同步的关系。当我们在本地搭建好一个全节点时，首先需要从其他节点把所有区块同步过来，目前以太坊mainnet链有600多万个区块，ropsten测试链有400多万个区块，具体的区块信息可以在Etherscan网站查询到。如果想要在链上发送一个交易，必须要等到本地区块链同步接近最新块，否则交易不会被广播出来。换句话说，区块链同步接近完成是进行交易的前提条件！这里用接近完成而不用完成是因为区块同步永远都不会完成，以太坊差不多10多秒就会产生一个新的区块。几百万个区块的同步是一个相当漫长且痛苦的过程，我目前同步的是ropsten测试链，也许是链上经常存在攻击，也许是中国这边节点少，同步过程相当不稳定，快的时候一晚上能同步50万个区块，慢的时候卡在某个区块一动不动好几天。因此非常有必要深入了解区块链的同步过程。 题外话不多说了，还是从BlockChainSync::syncPeer(）函数开始吧 123456789101112131415161718192021222324252627282930313233343536void BlockChainSync::syncPeer(std::shared_ptr&lt;EthereumPeer&gt; _peer, bool _force){ // ... if (m_state == SyncState::Waiting) return; u256 td = host().chain().details().totalDifficulty; if (host().bq().isActive()) td += host().bq().difficulty(); u256 syncingDifficulty = std::max(m_syncingTotalDifficulty, td); if (_force || _peer-&gt;m_totalDifficulty &gt; syncingDifficulty) { if (_peer-&gt;m_totalDifficulty &gt; syncingDifficulty) LOG(m_logger) &lt;&lt; \"Discovered new highest difficulty\"; // start sync m_syncingTotalDifficulty = _peer-&gt;m_totalDifficulty; if (m_state == SyncState::Idle || m_state == SyncState::NotSynced) { LOG(m_loggerInfo) &lt;&lt; \"Starting full sync\"; m_state = SyncState::Blocks; } _peer-&gt;requestBlockHeaders(_peer-&gt;m_latestHash, 1, 0, false); _peer-&gt;m_requireTransactions = true; return; } if (m_state == SyncState::Blocks) { requestBlocks(_peer); return; }} 开头有一个判断条件m_state == SyncState::Waiting，这是一个是否同步的开关，从别的节点peer同步过来的区块是放到一个缓存里的，当这个缓存满的时候，开关关闭，同步会暂时中止。 12345u256 td = host().chain().details().totalDifficulty;if (host().bq().isActive()) td += host().bq().difficulty();u256 syncingDifficulty = std::max(m_syncingTotalDifficulty, td); 这段代码是计算本地当前同步的区块链的总难度。 区块链矿工竞争是通过难度来衡量的，所有节点倾向于相信难度大的区块 如果该节点peer的总难度比我自身难度大，那么就需要从该节点同步(这里有一个漏洞，如果有人伪造一个非常大的难度，那么本节点会一直从对方同步，直到一个新的更大难度的节点出现，这样可能会导致同步卡住) m_state表示同步的状态，当m_state为SyncState::Idle或者SyncState::NotSynced时，同步就真正开始了！ 区块分为区块头和区块体，这两部分是分别下载的。 首先下载的是对方节点最新块的区块头，也就是： 1_peer-&gt;requestBlockHeaders(_peer-&gt;m_latestHash, 1, 0, false); 这里调用的是EthereumPeer::requestBlockHeaders()函数。反之如果该节点难度没有我自身难度大，并且之前同步过区块头的话，就准备同步区块体，也就是： 12345if (m_state == SyncState::Blocks){ requestBlocks(_peer); return;} 我们先来看看EthereumPeer::requestBlockHeaders()函数的实现。 在EthereumPeer类里有两个requestBlockHeaders()函数，分别是按区块号来同步和按区块hash值来同步，这里调用的是后者。 1234567891011void EthereumPeer::requestBlockHeaders(h256 const&amp; _startHash, unsigned _count, unsigned _skip, bool _reverse){ // ... setAsking(Asking::BlockHeaders); RLPStream s; prep(s, GetBlockHeadersPacket, 4) &lt;&lt; _startHash &lt;&lt; _count &lt;&lt; _skip &lt;&lt; (_reverse ? 1 : 0); LOG(m_logger) &lt;&lt; \"Requesting \" &lt;&lt; _count &lt;&lt; \" block headers starting from \" &lt;&lt; _startHash &lt;&lt; (_reverse ? \" in reverse\" : \"\"); m_lastAskedHeaders = _count; sealAndSend(s);} 这个函数比较简单，就是向对方发送一个GetBlockHeadersPacket数据包。那么对方接到这个包以后怎么回应呢？照例到EthereumPeer::interpret()函数里去找： 12345678910111213141516171819202122232425case GetBlockHeadersPacket:{ /// Packet layout: /// [ block: { P , B_32 }, maxHeaders: P, skip: P, reverse: P in { 0 , 1 } ] const auto blockId = _r[0]; const auto maxHeaders = _r[1].toInt&lt;u256&gt;(); const auto skip = _r[2].toInt&lt;u256&gt;(); const auto reverse = _r[3].toInt&lt;bool&gt;(); auto numHeadersToSend = maxHeaders &lt;= c_maxHeadersToSend ? static_cast&lt;unsigned&gt;(maxHeaders) : c_maxHeadersToSend; if (skip &gt; std::numeric_limits&lt;unsigned&gt;::max() - 1) { cnetdetails &lt;&lt; \"Requested block skip is too big: \" &lt;&lt; skip; break; } pair&lt;bytes, unsigned&gt; const rlpAndItemCount = hostData-&gt;blockHeaders(blockId, numHeadersToSend, skip, reverse); RLPStream s; prep(s, BlockHeadersPacket, rlpAndItemCount.second).appendRaw(rlpAndItemCount.first, rlpAndItemCount.second); sealAndSend(s); addRating(0); break;} 可以看到这里主要是调用了hostData-&gt;blockHeaders()函数获取区块头，并回复对方BlockHeadersPacket数据包。其中hostData是EthereumHostData类指针，blockId可能有两个值，分别是区块号或者区块hash值，对应前面两个requestBlockHeaders()函数。maxHeaders是请求区块头的数量。我们再看看EthereumHostData::blockHeaders()函数实现：这个函数有点长，先贴一部分代码吧： 12345678910111213141516171819202122232425262728293031323334auto numHeadersToSend = _maxHeaders;auto step = static_cast&lt;unsigned&gt;(_skip) + 1;assert(step &gt; 0 &amp;&amp; \"step must not be 0\");h256 blockHash;if (_blockId.size() == 32) // block id is a hash{ blockHash = _blockId.toHash&lt;h256&gt;(); // ... if (!m_chain.isKnown(blockHash)) blockHash = {}; else if (!_reverse) { auto n = m_chain.number(blockHash); if (numHeadersToSend == 0) blockHash = {}; else if (n != 0 || blockHash == m_chain.genesisHash()) { auto top = n + uint64_t(step) * numHeadersToSend - 1; auto lastBlock = m_chain.number(); if (top &gt; lastBlock) { numHeadersToSend = (lastBlock - n) / step + 1; top = n + step * (numHeadersToSend - 1); } assert(top &lt;= lastBlock &amp;&amp; \"invalid top block calculated\"); blockHash = m_chain.numberHash(static_cast&lt;unsigned&gt;(top)); // override start block hash with the hash of the top block we have } else blockHash = {}; }} numHeadersToSend这个值是需要发送的最大区块头数量，_skip值为0，因此step值为1。接着判断_blockId里是区块hash还是区块号，贴出来的这部分代码是区块hash，处理区块号那部分代码类似，有兴趣可以自己去看。 12if (!m_chain.isKnown(blockHash)) blockHash = {}; 这里是判断如果该区块hash不在我本地区块链里，则不返回任何东西。_reverse值为false，取出blockHash对应的块号n，计算要取的最高块号top，再得到当前区块链最新块号lastBlock，判断边界条件，top值不能超过lastBlock，如果超过了则top=lastBlock，再算出top对应的块hash值blockHash。 注意这里的blockHash是最高块的hash值，为什么需要这个值呢？因为区块链里区块是像单向链表连接起来的，其中0号区块是创世区块，后续区块从1开始递增，每个区块里会记录上一级区块的hash值，相当于是指向父区块的指针，因此我们遍历的时候只能从后往前遍历。 接着往下看： 12345678910111213141516171819202122232425262728auto nextHash = [this](h256 _h, unsigned _step){ static const unsigned c_blockNumberUsageLimit = 1000; const auto lastBlock = m_chain.number(); const auto limitBlock = lastBlock &gt; c_blockNumberUsageLimit ? lastBlock - c_blockNumberUsageLimit : 0; // find the number of the block below which we don't expect BC changes. while (_step) // parent hash traversal { auto details = m_chain.details(_h); if (details.number &lt; limitBlock) break; // stop using parent hash traversal, fallback to using block numbers _h = details.parent; --_step; } if (_step) // still need lower block { auto n = m_chain.number(_h); if (n &gt;= _step) _h = m_chain.numberHash(n - _step); else _h = {}; } return _h;}; 这里定义了一个函数nextHash()，用来从后向前遍历区块hash的。_h是当前区块hash，_step值为1。可以看到这里对区块做了一个分段，进行了区别处理，如果_h所在区块与最新区块距离超过1000个块，则采用区块号递减方式来遍历，也就是按遍历数组的方式遍历，即_h = m_chain.numberHash(n - _step);，否则按单向链表的方式遍历，即_h = details.parent;。 最后一部分准备返回数据 123456789101112131415161718bytes rlp;unsigned itemCount = 0;vector&lt;h256&gt; hashes;for (unsigned i = 0; i != numHeadersToSend; ++i){ if (!blockHash || !m_chain.isKnown(blockHash)) break; hashes.push_back(blockHash); ++itemCount; blockHash = nextHash(blockHash, step);}for (unsigned i = 0; i &lt; hashes.size() &amp;&amp; rlp.size() &lt; c_maxPayload; ++i) rlp += m_chain.headerData(hashes[_reverse ? i : hashes.size() - 1 - i]);return make_pair(rlp, itemCount); 把需要返回的区块头放到rlp中，并统计返回的区块头数量itemCount。 从这里可以看到有时候itemCount是0的，也就是可以不返回任何区块头，在实际同步中会经常碰到这种情况。","link":"/2019/07/04/以太坊C-源码解析（五）区块链同步-1/"},{"title":"以太坊C++源码解析（五）区块链同步(4)","text":"继续上一节的内容，收到其他peer发过来的区块头之后，流程要怎么走了呢？还记得上一节BlockChainSync::onPeerBlockHeaders()函数的末尾是collectBlocks()和continueSync()两个函数吗？collectBlocks()由于没有可合并的区块，我们留到后面去讲，而continueSync()会调用syncPeer()这个函数，这次由于m_state状态已经是SyncState::Blocks，因此最终将会调用BlockChainSync::requestBlocks()函数。 12345if (m_state == SyncState::Blocks){ requestBlocks(_peer); return;} 这和我们思考的逻辑相符，下载完了区块头，这不就是要请求下载区块体了吗？因此我们来好好看看BlockChainSync::requestBlocks()这个函数，这也是一个非常重要的函数。照例来一段一段分析： 123456if (host().bq().knownFull()){ LOG(m_loggerDetail) &lt;&lt; \"Waiting for block queue before downloading blocks\"; pauseSync(); return;} 函数开头就是一个非常重要的开关，我们之前提到过下载的区块会暂时存放到一级缓冲区里，合并后再写入二级缓冲区BlockQueue，那么当BlockQueue满了怎么办？这里的处理是暂停同步，调用pauseSync()来设置m_state值为SyncState::Waiting，在几个重要的同步函数中检测这个值就可以停止区块下载了。 123456789101112131415161718192021auto header = m_headers.begin();h256s neededBodies;vector&lt;unsigned&gt; neededNumbers;unsigned index = 0;if (m_haveCommonHeader &amp;&amp; !m_headers.empty() &amp;&amp; m_headers.begin()-&gt;first == m_lastImportedBlock + 1){ while (header != m_headers.end() &amp;&amp; neededBodies.size() &lt; c_maxRequestBodies &amp;&amp; index &lt; header-&gt;second.size()) { unsigned block = header-&gt;first + index; if (m_downloadingBodies.count(block) == 0 &amp;&amp; !haveItem(m_bodies, block)) { neededBodies.push_back(header-&gt;second[index].hash); neededNumbers.push_back(block); m_downloadingBodies.insert(block); } ++index; if (index &gt;= header-&gt;second.size()) break; // Download bodies only for validated header chain }} 这段是确定需要下载哪些区块的区块体，我们自然会想到应该是那些已经下载区块头对应的区块体，没错！但是有三个前提条件。这三个条件为： m_haveCommonHeader !m_headers.empty() m_headers.begin()-&gt;first == m_lastImportedBlock + 1 其中第二个条件很容易理解且满足，主要是第一个和第三个条件，第一个条件的含义我在前面已经讲过，这个表示下载真正开始。第三个条件表示目前在m_headers里最低区块正是上次已经下载块的下一个块。 满足这三个条件以后才开始遍历m_headers里第一个连续区块区域，比如m_headers里目前存放的区块是[[区块3，区块4，区块5], [区块8，区块9]]，那么这里遍历的就是[区块3，区块4，区块5]]这三个连续区块。需要下载区块体的区块hash被记录到neededBodies里，neededNumbers记录对应的区块号，m_downloadingBodies里则记录当前正要下载区块体的区块号，避免重复下载相同的区块。 12345if (neededBodies.size() &gt; 0){ m_bodySyncPeers[_peer] = neededNumbers; _peer-&gt;requestBlockBodies(neededBodies);} 如果成功找到了需要下载区块体的区块，那么就调用requestBlockBodies去向对方请求。如果没有，那么就说明上面的三大条件没有满足，不能下载区块体，那么就继续下载区块头吧。 12345678910111213unsigned start = 0;if (!m_haveCommonHeader){ // download backwards until common block is found 1 header at a time start = m_lastImportedBlock; if (!m_headers.empty()) start = std::min(start, m_headers.begin()-&gt;first - 1); m_lastImportedBlock = start; m_lastImportedBlockHash = host().chain().numberHash(start); if (start &lt;= m_chainStartBlock + 1) m_haveCommonHeader = true; //reached chain start} 我在之前都多次讲过区块链同步过程中的回退现象，在区块链本身不稳定的情况下，这种回退十分常见，比如ropsten链，但是在主链上似乎很少见到。那么回退是什么时候发生的呢？就是在这里了。这里判断m_haveCommonHeader值为false就会发生回退，回退的过程是选取当前已经下载好的区块号和m_headers中最低区块的上一个区块之间取较小值作为新的同步起点start，也就是同步回退了，并将m_lastImportedBlock设为新的起点。如果已经退到链的起始块，那么退无可退了就只能前进了，将m_haveCommonHeader设为true。 如果m_haveCommonHeader值还是为false，也就是并没有退到头，这实际上是else分支的内容，我提前来讲是因为这段太简单，就一句话： _peer-&gt;requestBlockHeaders(start, 1, 0, false);试探性地向对方请求起点处的一个区块，如果这个区块还不能让m_haveCommonHeader值为true的话，那么就继续退。 如果m_haveCommonHeader值为true了，不管是之前就是true还是退到了头，那么就要认真准备下面需要下载哪些区块头了。 12345678start = m_lastImportedBlock + 1;auto next = m_headers.begin();unsigned count = 0;if (!m_headers.empty() &amp;&amp; start &gt;= m_headers.begin()-&gt;first){ start = m_headers.begin()-&gt;first + m_headers.begin()-&gt;second.size(); ++next;} 如果start小于m_headers里的最低块那就最好，否则将start设为第一个连续区块区域之后，并且next设为第二个连续区块区域的开始，如果还用上面那个例子，那么看起来就像这样：其中虚线框的区块6和区块7表示还没下载的区块。 12345678910111213141516171819202122232425262728while (count == 0 &amp;&amp; next != m_headers.end()){ count = std::min(c_maxRequestHeaders, next-&gt;first - start); while(count &gt; 0 &amp;&amp; m_downloadingHeaders.count(start) != 0) { start++; count--; } std::vector&lt;unsigned&gt; headers; for (unsigned block = start; block &lt; start + count; block++) if (m_downloadingHeaders.count(block) == 0) { headers.push_back(block); m_downloadingHeaders.insert(block); } count = headers.size(); if (count &gt; 0) { m_headerSyncPeers[_peer] = headers; assert(!haveItem(m_headers, start)); _peer-&gt;requestBlockHeaders(start, count, 0, false); } else if (start &gt;= next-&gt;first) { start = next-&gt;first + next-&gt;second.size(); ++next; }} 这段用来精确地确定start值和需要下载区块头数量count。 1count = std::min(c_maxRequestHeaders, next-&gt;first - start); 开始的时候count设置为第二个连续区块区域和第一个连续区块区域之间所有块，但是不能超过最大值c_maxRequestHeaders，然后排除掉已经统计过的区块： 12345while(count &gt; 0 &amp;&amp; m_downloadingHeaders.count(start) != 0){ start++; count--;} 并将满足条件的区块加入到headers中： 1234567std::vector&lt;unsigned&gt; headers;for (unsigned block = start; block &lt; start + count; block++) if (m_downloadingHeaders.count(block) == 0) { headers.push_back(block); m_downloadingHeaders.insert(block); } 如果headers大小不为0，则向peer请求start为起点，count为数量的区块头： 1234567count = headers.size();if (count &gt; 0){ m_headerSyncPeers[_peer] = headers; assert(!haveItem(m_headers, start)); _peer-&gt;requestBlockHeaders(start, count, 0, false);} 否则如果start超过了第二个连续区块区域，则将start设为第二个连续区块区域的末尾，next设置为第三个连续区块区域的开始，继续上面的流程： 12345else if (start &gt;= next-&gt;first){ start = next-&gt;first + next-&gt;second.size(); ++next;}","link":"/2019/07/04/以太坊C-源码解析（五）区块链同步-4/"},{"title":"以太坊C++源码解析（四）RLPStream类","text":"RLP是一种特殊的二进制编码解码方式，以太坊里数据包都是采用这种方式编码的，和传统的结构相比，RLP编码更节省空间，提高网络传输效率，缺点就是不太直观，这种编码解码原理介绍在下面这边文章里讲得很好，还附有python的实现代码：RLP编码和解码。但是在本文里我们来看看在C++里的实现。 RLPStream类和RLP类在libdevcore\\RLP.h和RLP.cpp文件中，前者负责编码，后者负责解码。 RLPStream类我们先来看看编码方式吧，RLP里面可以放两种数据，一种是字符串(Data)，另一种是列表(List)，字符串又分为单个字符和多个字符，我们一个一个来。 单个字符RLP类提供了这些方法来编码单个字符： 1234RLPStream&amp; append(unsigned _s) { return append(bigint(_s)); }RLPStream&amp; append(u160 _s) { return append(bigint(_s)); }RLPStream&amp; append(u256 _s) { return append(bigint(_s)); }RLPStream&amp; append(bigint _s); 可见单个字符先都会被转换为bigint，再进行转换。 123456789101112131415161718192021222324RLPStream&amp; RLPStream::append(bigint _i){ if (!_i) m_out.push_back(c_rlpDataImmLenStart); else if (_i &lt; c_rlpDataImmLenStart) m_out.push_back((byte)_i); else { unsigned br = bytesRequired(_i); if (br &lt; c_rlpDataImmLenCount) m_out.push_back((byte)(br + c_rlpDataImmLenStart)); else { auto brbr = bytesRequired(br); if (c_rlpDataIndLenZero + brbr &gt; 0xff) BOOST_THROW_EXCEPTION(RLPException() &lt;&lt; errinfo_comment(\"Number too large for RLP\")); m_out.push_back((byte)(c_rlpDataIndLenZero + brbr)); pushInt(br, brbr); } pushInt(_i, br); } noteAppended(); return *this;} 如果_i是0，则直接存入c_rlpDataImmLenStart，也就是0x80 如果_i小于0x80，则直接存入_i 否则计算存入_i所需要的字节数br，如果br小于c_rlpDataImmLenCount也就是8，则先存入br + 0x80，再调用pushInt(_i, br);存入_i 计算存入br所需的长度brbr，也就是_i长度的长度，将c_rlpDataIndLenZero + brbr存进去，即0xb7 + brbr，再调用pushInt(_i, br);存入_i 注意到后面还有个函数noteAppended();这个是用来处理列表长度的，后面再谈。 多个字符保存多个字符有下列方法： 12345RLPStream&amp; append(bytesConstRef _s, bool _compact = false);RLPStream&amp; append(bytes const&amp; _s) { return append(bytesConstRef(&amp;_s)); }RLPStream&amp; append(std::string const&amp; _s) { return append(bytesConstRef(_s)); }RLPStream&amp; append(char const* _s) { return append(std::string(_s)); }template &lt;unsigned N&gt; RLPStream&amp; append(FixedHash&lt;N&gt; _s, bool _compact = false, bool _allOrNothing = false) { return _allOrNothing &amp;&amp; !_s ? append(bytesConstRef()) : append(_s.ref(), _compact); } 方法都是先转换为字节数组bytesConstRef，然后再编码。 1234567891011121314151617181920RLPStream&amp; RLPStream::append(bytesConstRef _s, bool _compact){ size_t s = _s.size(); byte const* d = _s.data(); if (_compact) for (size_t i = 0; i &lt; _s.size() &amp;&amp; !*d; ++i, --s, ++d) {} if (s == 1 &amp;&amp; *d &lt; c_rlpDataImmLenStart) m_out.push_back(*d); else { if (s &lt; c_rlpDataImmLenCount) m_out.push_back((byte)(s + c_rlpDataImmLenStart)); else pushCount(s, c_rlpDataIndLenZero); appendRaw(bytesConstRef(d, s), 0); } noteAppended(); return *this;} 如果是压缩模式，则忽略数组_s开头的0 如果数组只有单个字符，并且该字符小于0x80，则直接存入该字符 否则如果数组长度小于0x38，也就是56，则先存入s + 0x80，再调用appendRaw(bytesConstRef(d, s), 0);存入数组本身 如果数组长度大于等于56，则先存入数组长度s的长度+0xb7，再存入数组长度s，再调用appendRaw(bytesConstRef(d, s), 0);存入数组本身 也调用了noteAppended(); 列表存入列表有这些方法： 123456template &lt;class _T&gt; RLPStream&amp; append(std::vector&lt;_T&gt; const&amp; _s) { return appendVector(_s); }template &lt;class _T&gt; RLPStream&amp; appendVector(std::vector&lt;_T&gt; const&amp; _s) { appendList(_s.size()); for (auto const&amp; i: _s) append(i); return *this; }template &lt;class _T, size_t S&gt; RLPStream&amp; append(std::array&lt;_T, S&gt; const&amp; _s) { appendList(_s.size()); for (auto const&amp; i: _s) append(i); return *this; }template &lt;class _T&gt; RLPStream&amp; append(std::set&lt;_T&gt; const&amp; _s) { appendList(_s.size()); for (auto const&amp; i: _s) append(i); return *this; }template &lt;class _T&gt; RLPStream&amp; append(std::unordered_set&lt;_T&gt; const&amp; _s) { appendList(_s.size()); for (auto const&amp; i: _s) append(i); return *this; }template &lt;class T, class U&gt; RLPStream&amp; append(std::pair&lt;T, U&gt; const&amp; _s) { appendList(2); append(_s.first); append(_s.second); return *this; } 我们选这个来看： 1template &lt;class _T&gt; RLPStream&amp; appendVector(std::vector&lt;_T&gt; const&amp; _s) { appendList(_s.size()); for (auto const&amp; i: _s) append(i); return *this; } 可见先是调用appendList(_s.size())存入列表大小，然后依次存入列表元素。但是当我们深入appendList()函数里时，发现不是这么回事： 12345678RLPStream&amp; RLPStream::appendList(size_t _items){ if (_items) m_listStack.push_back(std::make_pair(_items, m_out.size())); else appendList(bytes()); return *this;} 这里只是将列表元素个数和当前输出缓冲区大小放入了一个列表栈m_listStack里，并没有存入任何东西。那列表长度是什么时候放进m_out的呢？答案就是前面提到的noteAppended()函数。noteAppended()函数代码为： 12345678910111213141516171819202122232425262728293031323334void RLPStream::noteAppended(size_t _itemCount){ if (!_itemCount) return; while (m_listStack.size()) { /// ... m_listStack.back().first -= _itemCount; if (m_listStack.back().first) break; else { auto p = m_listStack.back().second; m_listStack.pop_back(); size_t s = m_out.size() - p; // list size auto brs = bytesRequired(s); unsigned encodeSize = s &lt; c_rlpListImmLenCount ? 1 : (1 + brs); auto os = m_out.size(); m_out.resize(os + encodeSize); memmove(m_out.data() + p + encodeSize, m_out.data() + p, os - p); if (s &lt; c_rlpListImmLenCount) m_out[p] = (byte)(c_rlpListStart + s); else if (c_rlpListIndLenZero + brs &lt;= 0xff) { m_out[p] = (byte)(c_rlpListIndLenZero + brs); byte* b = &amp;(m_out[p + brs]); for (; s; s &gt;&gt;= 8) *(b--) = (byte)s; } } _itemCount = 1; // for all following iterations, we've effectively appended a single item only since we completed a list. }} m_out中每存入一个字符或者一个字符串都要调用一次这个函数，这个函数是从后向前遍历m_listStack。 判断当前列表是否全部存完，如果没有存完则退出： 12if (m_listStack.back().first) break; 否则先计算列表成员在m_out中实际占用空间的大小： 1size_t s = m_out.size() - p; 再计算出要存入这个s所需空间的大小encodeSize。 将数组整体向后移动encodeSize个空间 1memmove(m_out.data() + p + encodeSize, m_out.data() + p, os - p); 将’s’编码并填进空位中。 RLPStream类将数据编码进m_out以后，就可以通过swapOut()函数导出为字节数组了。","link":"/2019/07/04/以太坊C-源码解析（四）RLPStream类/"},{"title":"明明白白以太坊Merkle Patricia Trie","text":"在以太坊数据结构中，Merkle Patricia Trie始终是个绕不过去的坎，世界状态，交易，交易收据等都是以这种树的形式存储在区块链数据库中，并将树root hash保存在区块头里。可以说不弄懂这种树的原理就没有办法真正明白以太坊的数据存储方式。 大家都知道在以太坊cpp版本和go版本采用的是levelDb这种数据库，这种数据库存储的是[key, value]对。而实际上以太坊存储的数据结构也是[key, value]对，以状态state为例，key是address，value是[nonce, balance, storageRoot, codeHash]。那么问题来了，以太坊为什么不直接按[key, value来存储数据，而要费那么大劲用树型结构来存储呢？答案是为了安全性。 而为了引进Merkle Patricia Trie，我们要先来看一种简单的树。 Radix Trees中文翻译为前缀树，这是一种用来查询的数据结构。每次遍历key的一个字符，直到找到对应的值。比如有下面几个数据：('do', 'verb'), ('dog', 'puppy'), ('doge', 'coin'), ('horse', 'stallion')，存储在Radix Trees里是这样的：其中圆圈里是值，key的字符组成查询路径，路径是doge时的查询过程为d-&gt;o-&gt;g-&gt;e，需要查询4次，而路径为horse时查询需要5次，因此这种树查询虽然可行，但是效率不高。我们后面可以看到以太坊是怎么解决这个问题的。解决了查询，然后为了安全性，我们引入了Merkle Trees。 Merkle TreesMerkle Trees又名Hash Trees，数据都存储在叶节点，父节点则存储叶节点的hash值，一级一级向上， 直到根节点。因此如果修改了叶节点的数据，则父节点hash值就会改变，根节点hash值也会改变，从而很快就可以验证数据是否正确。 保证数据不被篡改，这是区块链技术的基础。 Merkle Patricia Trie以太坊Merkle Patricia Trie是结合了上面两种树的数据结构，兼顾了查询和安全性。 查询前面不是说过Radix Trees查询效率不行吗？那就进行优化，将路径里相同部分提取出来，作为共同路径，从而减少树的高度，提供查询效率。还是用上面的例子，合并路径后的树变为：可以看到将do和horse作为共同路径后，查询doge的路径变成了do-&gt;g-&gt;e，只需要查询3次，而horse只需要查询一次就够了。 安全性节点与节点之间的联系不再采用内存指针的方式，而是采用hash值的方式，比如上图中的puppy这个值的节点存储执行下一个节点的hash值，然后将这个hash值与实际节点对应关系存储在[key, value]的数据库中。当有人篡改coin节点值时，也必须要修改puppy节点里的hash值，然后verb节点里hash值也需要修改，直到根节点，所以我们只需要验证根节点的hash值，就知道底层数据是否正确。 节点类型按功能不同，存在4种节点： NULL节点 分支节点，含有17项数据，[ v0 … v15, vt ] 叶节点，含有2项数据，[ encodedPath, value ] 扩展节点，含有两项数据，[ encodedPath, key ] Merkle Patricia Trie查询路径是以nibble(半个字节）作为单位。分支节点中的前16项数据v0-v15分别对应16进制的0-0xF，是用nibble作为索引，可以快速进行查询，比如路径nibble是0xa，则取分支节点0xa位置的值。分支节点对应图上的分叉节点。叶节点和扩展节点都是两项，只是value不同，那么怎么区分他们呢？以太坊是采用添加前缀的方式，根据节点类型和路径长度是否是奇偶数来添加不同的前缀。有一个对应表： hex char bits node type partial path length 0 0000 extension even(偶数) 1 0001 extension odd(奇数) 2 0010 terminating (leaf) even(偶数) 3 0011 terminating (leaf) odd(奇数) 可以看到前缀为0或者1时表示扩展节点，2或者3时表示叶节点。另外前缀为0或者2时，需要变更为00或20. 例子1我们用一个例子来说明：图中右上角有4个[key, value]对，我们要存储这4对数据。key每个方框里是一个nibble。 从这四个路径中可以提取出公共路径a7，因此可以建立一个扩展节点A, [00 a7, hashB]，a7是一个偶数长度的扩展节点，前缀为00，hashB是下一个节点B的hash值。 下一个nibble取值有1, 7, f，因此节点B为一个分支节点，其中index为1，7，f的位置保存下一个节点的hash值，value为空。这个分支节点为：[ EMPTY, hashC, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, hashD, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, hashE, value]。hashC, hashD, hashE为下一层节点的hash值 因为出现了分支，我们来看1这个分支，这个分支后没有分支，所以后续的1355可以作为一个叶节点，为[20 1355, 45.0ETH]，这里1355为偶数长度的叶节点，所以前缀为20。 再来看7这个分支，后续又有d3这共同路径，因此创建一个扩展节点D，[00 d3, hashF]，’d3’是一个偶数长度的扩展节点，前缀为00，hashF是下一个节点F的hash值。 d3之后又出现分支3和9，因此又出现一个分支节点，其中index为3和9的位置保存下一个节点的hash值，value为空。这个节点为：[ EMPTY, EMPTY, EMPTY, hashG, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, hashH, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, value] 剩下的就是两个叶节点，分别为[37, 1.00WEI]和[37, 0.12ETH]，这两个都是奇数长度的叶节点，因此前缀为3。 其他节点可以按同样的方法分析。 例子2我们再用前面的('do', 'verb'), ('dog', 'puppy'), ('doge', 'coin'), ('horse', 'stallion')做例子来说明分析过程。由于是采用nibble作为路径单位，所以先将路径和值都写为字节形式： 1234&lt;64 6f&gt; : &apos;verb&apos;&lt;64 6f 67&gt; : &apos;puppy&apos;&lt;64 6f 67 65&gt; : &apos;coin&apos;&lt;68 6f 72 73 65&gt; : &apos;stallion&apos; 那么在数据库中存储形式为： 12345678rootHash: [ &lt;16&gt;, hashA ]hashA: [ &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, hashB, &lt;&gt;, &lt;&gt;, &lt;&gt;, hashC, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt; ]hashC: [ &lt;20 6f 72 73 65&gt;, &apos;stallion&apos; ]hashB: [ &lt;00 6f&gt;, hashD ]hashD: [ &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, hashE, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &apos;verb&apos; ]hashE: [ &lt;17&gt;, hashF ]hashF: [ &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, hashG, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &apos;puppy&apos; ]hashG: [ &lt;35&gt;, &apos;coin&apos; ] 我们来模拟一下真实的查询过程，假如我们要查询doge这个key对应的值是多少。 rootHash已知(存储在区块头中)，那么从levelDb中读出key为rootHash的值，也就是[ &lt;16&gt;, hashA ]，这是一个扩展节点，路径为6，剩下路径为4,6,f,6,7,6,5，并得到下一个节点hashA 在levelDb中读出key为hashA的值，也就是 [ &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, hashB, &lt;&gt;, &lt;&gt;, &lt;&gt;, hashC, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt; ]，nibble为4，在位置4读出下一个节点hashB，剩余路径为6,f,6,7,6,5 在levelDb中读出key为hashB的值，也就是[ &lt;00 6f&gt;, hashD ]，这是一个路径为6f的扩展节点，因此剩余路径为6,7,6,5，并得到下一个节点hashD 在levelDb中读出key为hashD的值，也就是 [ &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, hashE, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, ‘verb’ ]，nibble为6，在位置6读出下一个节点hashE，剩余路径为7,6,5 在levelDb中读出key为hashE的值，也就是 [ &lt;17&gt;, hashF ]，这是一个路径为7的扩展节点，因此剩余路径为65，并得到下一个节点hashF 在levelDb中读出key为hashF的值，也就是[ &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, hashG, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, ‘puppy’ ]，nibble为6，在位置6读出下一个节点hashG，剩余路径为5 在levelDb中读出key为hashG的值，也就是[ &lt;35&gt;, ‘coin’ ]，这是一个路径为5的叶节点，正好和我们的剩余路径吻合，因此我们就得到了最终的值coin。 可见以太坊为了安全性真的增加了不少复杂性，降低了效率。 以太坊中的应用以太坊中实际情况还要复杂，数据还需要通过RLP编码。 State Trie(世界状态树)路径是sha3(ethereumAddress)，value是rlp([nonce,balance,storageRoot,codeHash]) Transactions Trie(交易树)路径是rlp(transactionIndex)，value是rlp(transaction) Receipts Trie(交易收据树)路径是rlp(transactionIndex)，value是rlp(transaction receipt) 参考Understanding Trie Databases in EthereumModified Merkle Patricia Trie Specification (also Merkle Patricia Tree)","link":"/2019/07/11/明明白白以太坊Merkle-Patricia-Trie/"}],"tags":[{"name":"以太坊","slug":"以太坊","link":"/tags/以太坊/"},{"name":"以太坊 C++ 源码","slug":"以太坊-C-源码","link":"/tags/以太坊-C-源码/"}],"categories":[{"name":"区块链","slug":"区块链","link":"/categories/区块链/"},{"name":"以太坊C++源码解析","slug":"以太坊C-源码解析","link":"/categories/以太坊C-源码解析/"}]}